{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **파트 2: 전통적 인과추론 방법론**\n",
        "\n",
        "---\n",
        "\n",
        "# 7. 인과추론의 기본 원칙 (Foundational Principles of Causal Inference)\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- \"X가 Y의 원인이다\"라고 말하는 것은, \"만약 X가 달라졌더라면, Y도 달라졌을 것이다\"라는 **'반사실적 가상(Counterfactual)'**을 의미한다.\n",
        "- 인과추론의 모든 방법론은, 현실에서는 결코 관찰할 수 없는 이 '반사실적 가상'을 **데이터를 이용해 어떻게 하면 가장 설득력 있게 추정해낼 수 있을까**에 대한 고민이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **인과추론의 근본 문제 (The Fundamental Problem of Causal Inference)**\n",
        "- **정의**: 특정 개인(또는 회사, 국가)에 대해, 우리는 **오직 하나의 결과**만을 관찰할 수 있다.\n",
        "- **예시**: A라는 환자는 신약을 '복용했다'. 우리는 A가 신약을 복용하고 병이 나았는지(Y=1) 낫지 않았는지(Y=0)만 관찰할 수 있다.\n",
        "- **문제**: A라는 환자가 **\"만약 그 약을 복용하지 않았더라면\"** 어떻게 되었을지는 **영원히 관찰할 수 없다.** 이것이 바로 우리가 알고 싶은 '반사실적 가상'이며, 인과추론의 모든 어려움은 여기서 시작된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **잠재적 결과 프레임워크 (Potential Outcomes Framework)**\n",
        "- 이 근본 문제를 다루기 위해 경제학자들이 사용하는 생각의 틀.\n",
        "- 모든 개체 $i$는, 처치(treatment) 여부에 따라 두 가지의 **'잠재적 결과(potential outcomes)'**를 모두 가지고 있다고 상상한다.\n",
        "    - $Y_i(1)$: 개체 $i$가 처치를 **받았을 경우**의 잠재적 결과. (A 환자가 신약을 복용했을 때의 건강 상태)\n",
        "    - $Y_i(0)$: 개체 $i$가 처치를 **받지 않았을 경우**의 잠재적 결과. (A 환자가 신약을 복용하지 않았을 때의 건강 상태)\n",
        "- **개인 수준의 인과 효과 (Individual Treatment Effect)**: $\\tau_i = Y_i(1) - Y_i(0)$\n",
        "    - (하지만 우리는 둘 중 하나만 관찰할 수 있으므로, 개인 수준의 인과 효과는 절대 정확히 알 수 없다.)\n",
        "- **인과추론의 목표**: 개인 수준이 아닌, **'집단의 평균적인' 인과 효과**를 추정하는 것.\n",
        "    - **ATE (Average Treatment Effect, 평균 처치 효과)**: $E[\\tau_i] = E[Y_i(1) - Y_i(0)]$\n",
        "    - 모집단 전체에서 처치의 평균적인 효과.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **선택 편향: 인과추론의 가장 큰 적 (Selection Bias)**\n",
        "- **가장 흔한 실수**: (약을 먹은 사람들의 평균 결과) - (약을 먹지 않은 사람들의 평균 결과)를 계산하는 것.\n",
        "- **문제**: 약을 먹기로 '선택'한 사람들과 먹지 않기로 '선택'한 사람들은 약 복용 여부 외에도 원래부터 다른 특성을 가질 수 있다. (예: 약을 챙겨 먹는 사람들이 원래 더 건강에 신경 쓰는 사람들일 수 있다.)\n",
        "- **수식으로 표현된 선택 편향**:\n",
        "    $$\n",
        "    \\underbrace{E[Y|D=1] - E[Y|D=0]}_\\text{단순한 평균 차이} = \\underbrace{E[Y(1)-Y(0)|D=1]}_\\text{처치 받은 자들의 진짜 효과(ATT)} + \\underbrace{\\{ E[Y(0)|D=1] - E[Y(0)|D=0] \\}}_\\text{선택 편향}\n",
        "    $$\n",
        "- **선택 편향의 의미**: 처치를 받지 않았더라도, 원래부터 두 그룹 간에 존재했을 결과의 차이. **이 선택 편향을 0으로 만드는 것이 모든 인과추론 방법론의 최종 목표이다.**\n",
        "\n",
        "<br>\n",
        "\n",
        "### **인과추론의 전략: 식별과 추정 (Identification and Estimation)**\n",
        "- **식별 (Identification)**: \"어떤 **가정(assumption)** 하에서, 어떤 **연구 설계(research design)**를 사용하면, 우리가 가진 데이터로부터 선택 편향을 제거하고 순수한 인과 효과를 골라낼 수 있는가?\"에 대한 논리적 전략.\n",
        "    - RCT, DID, RDD, IV 등은 모두 이 '식별 전략'의 종류이다.\n",
        "- **추정 (Estimation)**: 식별 전략이 세워진 후에, 실제 데이터를 가지고 인과 효과의 구체적인 숫자 값을 계산하는 통계적 과정.\n",
        "    - OLS, 로짓, GLS 등은 이 '추정' 단계에서 사용되는 계산 '도구'이다."
      ],
      "metadata": {
        "id": "k5XpSO38ov1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 무작위 통제 실험 (Randomized Controlled Trial, RCT)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 인과관계를 추론하는 데 가장 큰 적인 **'누락 변수 편향(OVB)'을 원천적으로 제거**하는 가장 완벽하고 이상적인 방법.\n",
        "- **'무작위 배정(Random Assignment)'**이라는 강력한 장치를 통해, 처치(treatment)를 받는 그룹과 받지 않는 그룹을 모든 면에서 '쌍둥이'처럼 똑같이 만들어 버리는 것이다.\n",
        "- 두 그룹은 평균적으로 관찰 가능한 특성(나이, 성별 등)뿐만 아니라, **관찰 불가능한 특성(능력, 성실함, 의지 등)까지도 동일**해진다.\n",
        "- 따라서, 실험 후에 두 그룹 간에 나타나는 결과의 차이는 **오직 '처치'의 효과 때문**이라고 확신할 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **RCT의 과정**\n",
        "1.  **모집단 정의**: 실험의 대상이 될 전체 그룹을 정의한다. (예: 특정 지역의 구직자 1,000명)\n",
        "2.  **무작위 배정**: 동전 던지기와 같은 무작위적인 방식으로, 이들을 **처치 집단(Treatment Group)**과 **통제 집단(Control Group)**으로 나눈다.\n",
        "3.  **처치 실행**: 처치 집단에게만 특정 정책이나 개입(예: 새로운 직업 훈련 프로그램)을 시행한다. 통제 집단은 아무것도 하지 않는다.\n",
        "4.  **결과 측정**: 일정 시간이 지난 후, 두 집단의 결과 변수(예: 취업률, 평균 임금)를 모두 측정한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **분석 방법 (매우 간단함)**\n",
        "- 무작위 배정 덕분에, 분석은 두 그룹의 **결과값 평균을 비교**하는 것만으로 충분하다.\n",
        "\n",
        "$$ \\text{ATE (평균 처치 효과)} = E[Y_i | D_i=1] - E[Y_i | D_i=0] $$\n",
        "\n",
        "- $E[Y_i | D_i=1]$: 처치 집단의 평균 결과 (예: 직업 훈련을 받은 사람들의 평균 임금)\n",
        "- $E[Y_i | D_i=0]$: 통제 집단의 평균 결과 (예: 직업 훈련을 받지 않은 사람들의 평균 임금)\n",
        "\n",
        "> (※ 이를 $Y_i = \\beta_0 + \\beta_1 D_i + u_i$ 라는 간단한 OLS 회귀식으로 분석할 수도 있다. 여기서 $D_i$는 처치 집단이면 1, 통제 집단이면 0인 더미 변수이다. 무작위 배정 덕분에 $D_i$와 오차항 $u_i$는 아무런 관련이 없으므로(OVB가 없으므로), $\\hat{\\beta}_1$은 정확히 위에서 계산한 평균 처치 효과(ATE)와 같아진다.)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점 및 단점**\n",
        "\n",
        "- **장점**:\n",
        "    - **인과추론의 왕 (Gold Standard)**: 선택 편향(selection bias)과 누락 변수 편향(OVB) 문제를 완벽하게 해결하여, 이론적으로 가장 깔끔하게 인과관계를 증명할 수 있다.\n",
        "    - **분석의 단순함**: 그룹 간 평균 비교라는 매우 간단하고 직관적인 방법으로 효과를 분석할 수 있다.\n",
        "\n",
        "- **단점 및 현실적 한계**:\n",
        "    - **윤리적 문제**: \"흡연이 건강에 미치는 영향\"을 보기 위해 사람들에게 무작위로 흡연을 강요할 수는 없다.\n",
        "    - **비용과 시간**: 실제 실험을 설계하고 실행하는 데에는 막대한 비용과 오랜 시간이 소요된다.\n",
        "    - **일반화의 문제 (Generalizability)**: 특정 집단을 대상으로 한 실험의 결과가, 다른 집단이나 사회 전체에 동일하게 적용된다고 보장하기 어렵다.\n",
        "    - **중도 탈락 문제 (Attrition)**: 실험 도중 사람들이 중도에 이탈하면, 처치 집단과 통제 집단의 동질성이 깨져 결과가 왜곡될 수 있다.\n",
        "\n",
        "(※ 바로 이러한 RCT의 현실적 한계 때문에, 우리는 현실 세계에서 발생하는 사건들이 마치 '자연적인 실험(Natural Experiment)'처럼 보이는 상황을 찾아내어 분석하는 **DID, RDD, IV** 와 같은 **준실험적(quasi-experimental)** 방법론들을 필요로 하게 된다.)"
      ],
      "metadata": {
        "id": "3_4v18CIU0EH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. 이중차분법 (Difference-in-Differences, DID)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 특정 정책(treatment)의 효과를 평가하고 싶을 때, 그 정책의 영향을 받은 **'처치 집단(Treatment Group)'**과 영향을 받지 않은 **'통제 집단(Control Group)'**을 설정하고, **정책 시행 전(Before)과 후(After)**의 결과 변화를 비교하는 방법.\n",
        "- 핵심은, 단순히 '정책 시행 후 두 집단의 차이'를 보는 것이 아니라, **\"정책이 없었을 때 나타났을 두 집단의 변화량 차이\"**를 통제하는 데 있다.\n",
        "- 이름 그대로 **두 번의 차이(difference)를 계산**한다.\n",
        "    1.  **첫 번째 차이**: 각 그룹 내에서 '시행 후'와 '시행 전'의 차이를 계산한다. (시간의 흐름에 따른 자연적인 변화량)\n",
        "    2.  **두 번째 차이**: 이렇게 구한 두 그룹의 '변화량' 간의 차이를 계산한다. 이 마지막 차이가 바로 우리가 원하는 정책의 순수한 인과 효과라고 추정한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **DID의 직관적 예시**\n",
        "\n",
        "- **연구 질문**: \"A 도시에서 최저임금을 인상한 정책이 고용에 미치는 영향은?\"\n",
        "- **설계**:\n",
        "    - **처치 집단**: 최저임금을 인상한 A 도시\n",
        "    - **통제 집단**: 최저임금을 인상하지 않은, A 도시와 매우 유사한 B 도시\n",
        "- **데이터**: 정책 시행 전/후, 두 도시의 음식점 평균 고용자 수\n",
        "\n",
        "| 도시 | 시행 전 (2024년) | 시행 후 (2025년) | **변화량 (후 - 전)** |\n",
        "| :--- | :---: | :---: | :---: |\n",
        "| **A (처치)** | 20명 | 22명 | +2명 |\n",
        "| **B (통제)** | 18명 | 21명 | +3명 |\n",
        "| **차이 (A - B)** | 2명 | 1명 | **-1명** |\n",
        "\n",
        "- **잘못된 분석**: 시행 후만 보면, A 도시(22명)가 B 도시(21명)보다 고용이 1명 많다.\n",
        "- **DID 분석**:\n",
        "    1.  **A 도시의 변화**: +2명\n",
        "    2.  **B 도시의 변화**: +3명 (이것이 바로 정책이 없었더라도 나타났을 '자연적인 경기 호황 효과'이다.)\n",
        "    3.  **두 변화량의 차이 (두 번째 차이)**: (+2명) - (+3명) = **-1명**\n",
        "- **결론**: 최저임금 인상 정책은, 자연적인 경기 호황 효과를 고려했을 때, 오히려 **고용을 평균적으로 1명 감소시키는 효과**를 가졌다고 추정할 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **핵심 가정: 공통 추세 가정 (Parallel Trends Assumption)**\n",
        "- DID 추정치가 인과 효과로 해석되기 위한, **가장 중요하고 핵심적인 단 하나의 가정**.\n",
        "- **의미**: **만약 처치 집단에 정책이 시행되지 않았더라면,** 처치 집단의 결과 변수 변화 추세는 통제 집단의 변화 추세와 **똑같았을 것이다.**\n",
        "- **위 예시에서의 의미**: \"A 도시에 최저임금 인상이 없었더라면, A 도시의 고용자 수도 B 도시처럼 3명 증가했을 것이다.\"\n",
        "- **검증 방법**: 정책 시행 **이전(pre-treatment) 기간**에 두 그룹의 추세가 실제로 평행했는지를 시각적으로(그래프로) 확인하는 '사전 추세 검정(Pre-trend test)'을 수행한다. 만약 시행 전부터 두 그룹의 추세가 달랐다면, 공통 추세 가정이 성립하지 않을 가능성이 높으므로 DID 분석의 신뢰도가 크게 떨어진다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **회귀분석을 이용한 DID 분석**\n",
        "DID는 간단한 OLS 회귀식으로도 쉽게 구현할 수 있다.\n",
        "\n",
        "$$ Y_{it} = \\beta_0 + \\beta_1 Treat_i + \\beta_2 Post_t + \\beta_3 (Treat_i \\times Post_t) + u_{it} $$\n",
        "\n",
        "- $Y_{it}$: 개체 $i$의 시간 $t$에서의 결과 변수 (예: 도시 $i$의 $t$년도 고용)\n",
        "- $Treat_i$: 처치 집단이면 1, 통제 집단이면 0인 **더미 변수**.\n",
        "- $Post_t$: 정책 시행 후 기간이면 1, 이전 기간이면 0인 **더미 변수**.\n",
        "- **$Treat_i \\times Post_t$**: **상호작용 항(Interaction Term)**. 처치 집단이면서 동시에 정책 시행 후 기간일 때만 1의 값을 갖는다.\n",
        "- **$\\beta_3$의 의미**: 이 계수가 바로 우리가 찾고 있는 **DID 추정치 (ATE)** 이다.\n"
      ],
      "metadata": {
        "id": "NrMNkLTFK9hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. 시차를 둔 이중차분법 (Staggered Difference-in-Differences)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### **핵심 아이디어**\n",
        "- 전통적인 DID는 모든 처치 집단이 **'동시에(at the same time)'** 정책의 영향을 받을 때를 가정한 것이다.\n",
        "- **시차를 둔 DID(Staggered DID)**는 그룹마다 **정책 도입 시점이 제각각 다른, 더 현실적이고 복잡한 상황**을 다루기 위한 현대적인 DID 방법론이다.\n",
        "- (예시: A시는 2020년에, B시는 2022년에, C시는 2024년에 각각 보조금 정책을 도입하는 경우)\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **무엇이 문제인가?: 기존 DID 회귀분석의 함정**\n",
        "- 위와 같은 시차를 둔 상황에서, 이전에 배운 단순한 DID 회귀식(`Y ~ Treat * Post`)을 그대로 사용하면 **심각한 편향**이 발생할 수 있다는 사실이 최근(2020년경)에 밝혀졌다.\n",
        "- **핵심적인 문제**: **'나쁜 통제 집단(Bad Control Group)'** 문제.\n",
        "    - 단순 회귀분석은 특정 시점에 '아직 처치를 받지 않은' 모든 그룹을 통제 집단으로 간주한다.\n",
        "    - 예를 들어, 2022년에 정책이 도입된 **B시의 효과를 분석**할 때, 회귀분석은 **2020년에 이미 정책이 도입된 A시**마저 '통제 집단'의 일부로 사용해버리는 오류를 범한다.\n",
        "    - 하지만 A시는 이미 정책의 영향을 받은 그룹이므로, 더 이상 정책 효과가 없었을 경우의 '공통 추세'를 대표하는 깨끗한 통제 집단이 될 수 없다.\n",
        "    - 이로 인해 정책 효과가 과대 또는 과소 추정될 수 있으며, 심지어 효과의 부호가 반대로 나타나는 최악의 경우도 발생할 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **해결책: Callaway & Sant'Anna (2021) 등의 접근법**\n",
        "- 이 문제를 해결하기 위해 Callaway & Sant'Anna 등의 경제학자들이 제안한 새로운 방법론의 핵심은, **\"문제를 더 작게, 그리고 더 명확하게 정의하여 푸는 것\"**이다. 하나의 거대한 회귀분석 대신, 여러 개의 깔끔한 비교를 수행하고 이를 마지막에 합치는 방식을 사용한다.\n",
        "\n",
        "- **작동 원리**:\n",
        "    1.  **그룹 재정의**: 처치를 받은 시점을 기준으로 그룹을 나눈다. (예: '2020년 도입 그룹', '2022년 도입 그룹')\n",
        "    2.  **'깨끗한' 통제 집단 사용**: 각 처치 그룹의 효과를 계산할 때, **오직 '아직 처치를 받지 않은 그룹(not-yet-treated)' 또는 '영원히 처치를 받지 않는 그룹(never-treated)'**만을 통제 집단으로 사용한다. 이를 통해 '나쁜 통제 집단' 문제를 원천적으로 차단한다.\n",
        "    3.  **효과를 잘게 나누어 추정**: 각 그룹별, 시간대별 정책 효과(**GATT**: Group-Time Average Treatment Effects)를 각각 따로 추정한다. (예: 2020년 그룹의 2020년 효과, 2020년 그룹의 2021년 효과 등)\n",
        "    4.  **결과를 의미 있게 재조합**: 이렇게 잘게 추정한 수많은 효과들을, 연구자의 목적에 맞게 다시 합쳐서 보여준다.\n",
        "        - **이벤트 스터디 플롯**: 정책 도입 시점을 기준으로 효과가 시간에 따라 어떻게 변하는지 보여주는 것이 가장 일반적인 방식이다.\n",
        "        - **전체 평균 효과**: 모든 그룹-시간 효과를 종합한 단일한 평균 처치 효과를 계산한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **실용적인 결론 및 시사점**\n",
        "- 현대 응용미시경제학 연구에서 **정책 도입 시점이 그룹마다 다르다면, Staggered DID 방법론을 사용하는 것이 사실상의 표준(de facto standard)**으로 자리 잡았다.\n",
        "- 단순 DID 회귀분석을 사용하는 것은 더 이상 학문적 정당성을 얻기 어려우며, 논문 심사 과정에서 반드시 지적받게 된다.\n",
        "- 분석을 위해서는 `did`, `fixest`(R), `DiD`(Python) 등 Staggered DID를 위해 특별히 개발된 전용 라이브러리를 사용해야 한다."
      ],
      "metadata": {
        "id": "dXSreYEirI-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. 회귀 불연속 설계 (Regression Discontinuity Design, RDD)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 세상에는 어떤 **명확한 '경계선(cutoff)'**을 기준으로 혜택이나 처치(treatment)가 주어지는 규칙이 매우 많다. (예: \"시험 점수 80점 이상이면 장학금\", \"나이 65세 이상이면 연금\")\n",
        "- 이 **경계선 바로 양옆에 있는 사람들**은 사실상 거의 모든 면에서 똑같은 사람들이라고 볼 수 있다. (예: 79.9점을 받은 학생과 80.1점을 받은 학생은 실력, 노력, 배경 등에서 거의 차이가 없다.)\n",
        "- 즉, 경계선 바로 근처에서는 누가 처치를 받고 못 받는지가 마치 **'무작위(random)'**로 결정된 것과 같은 효과가 나타난다.\n",
        "- 이 점을 이용하여 경계선 양쪽의 결과를 비교함으로써, 처치의 순수한 인과 효과를 추정하는 방법이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **작동 원리: 경계선 근처의 '준-무작위 배정'**\n",
        "- **잘못된 비교**: 장학금을 받은 모든 학생(80점 이상)과 못 받은 모든 학생(80점 미만)을 비교하면 심각한 OVB가 발생한다. 당연히 80점 이상인 학생들이 원래 더 똑똑하고 성실할 것('능력'이라는 누락 변수).\n",
        "- **RDD의 해법**: 전체를 비교하지 않고, 오직 **경계선 바로 근처(local area)**에 있는 샘플에만 집중한다.\n",
        "- 79.9점과 80.1점의 차이는 실력의 차이라기보다, 시험 당일의 컨디션, 찍기 운 등 **우연(luck)**에 의해 갈렸을 가능성이 높다.\n",
        "- 따라서 이 경계선 주변에서는 처치 집단과 통제 집단이 **마치 RCT처럼 무작위로 배정**된 것과 같다고 가정할 수 있고, 두 그룹의 결과 차이는 오직 '장학금' 때문이라고 주장할 수 있게 된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **RDD의 종류**\n",
        "\n",
        "1.  **명확한 RDD (Sharp RDD)**: 경계선을 기준으로 처치 여부가 100% 결정되는 경우. (80점 이상은 '모두' 받고, 80점 미만은 '아무도' 못 받음)\n",
        "2.  **불명확한 RDD (Fuzzy RDD)**: 경계선을 기준으로 처치를 받을 '자격'이나 '확률'이 변하는 경우. (65세 이상은 연금을 신청할 '자격'이 생기지만, 실제로 신청해서 받는 사람은 일부일 수 있음)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **직관적 예시 및 시각화: 장학금과 성적**\n",
        "\n",
        "- **연구 질문**: \"성적 우수 장학금(treatment)이 학생들의 다음 학기 성적(outcome)에 미치는 영향은?\"\n",
        "- **설계**:\n",
        "    - **배정 변수 (Running Variable)**: 이전 학기 성적\n",
        "    - **경계선 (Cutoff)**: 80점\n",
        "- **분석**: RDD 분석의 결과는 보통 그래프로 보여줄 때 가장 강력하다.\n",
        "    - X축: 이전 학기 성적 (경계선을 0으로 표준화)\n",
        "    - Y축: 다음 학기 성적\n",
        "    - 그래프를 그렸을 때, 경계선인 80점에서 **Y값의 뚜렷한 '점프(jump)' 또는 '단절(discontinuity)'**가 관찰된다면, 이 점프의 크기가 바로 장학금의 인과 효과가 된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **주요 가정 및 위협 요인**\n",
        "\n",
        "RDD의 신뢰성은 다음 두 가지 핵심 가정에 달려있다.\n",
        "\n",
        "1.  **배정 변수 조작 불가 (No Manipulation)**\n",
        "    - **의미**: 사람들이 자신의 이익을 위해 배정 변수를 **의도적으로, 그리고 정확하게 조작할 수 없어야 한다.**\n",
        "    - **위협**: 만약 학생들이 자신의 점수가 79점이라는 것을 알고, 교수님께 부탁해 점수를 80점으로 쉽게 올릴 수 있다면, 경계선 양쪽의 그룹은 더 이상 동질적이지 않게 된다. (적극적인 학생들이 80점 근처에 몰려 있을 것)\n",
        "\n",
        "2.  **다른 요인들의 연속성 (Continuity of Other Factors)**\n",
        "    - **의미**: 결과(Y)에 영향을 미칠 수 있는 다른 어떤 요인도, 바로 그 경계선에서 불연속적으로 변해서는 안 된다.\n",
        "    - **위협**: 만약 \"성적 80점\"이 장학금 지급 기준이면서, 동시에 '우수 학생 기숙사' 입사 기준이라면, 나중에 나타나는 성적 향상이 '장학금' 때문인지 '더 좋은 기숙사 환경' 때문인지 구분할 수 없게 된다."
      ],
      "metadata": {
        "id": "GenMVxZXMOHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. 도구변수법 (Instrumental Variables, IV)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 우리가 관심 있는 독립변수(X)가 누락 변수 편향(OVB) 등으로 인해 **'오염(contaminated)'**되어, 인과 효과 추정에 직접 사용할 수 없는 상황을 가정한다. (이를 '내생성(Endogeneity)'을 가졌다고 한다.)\n",
        "- 이때, 이 오염된 변수(X)와는 관련이 깊지만, 결과(Y)와는 직접적인 관련이 없는 **깨끗하고 믿을 수 있는 제3의 변수, 즉 '도구(instrument)'(Z)를 이용**하여 X의 효과를 간접적으로 추론하는 방법.\n",
        "- **비유**: 오염된 증인(X)의 증언을 직접 믿을 수는 없지만, 그 증인(X)에게만 영향을 줄 수 있고 사건 현장(Y)과는 무관한, 매우 신뢰도 높은 제3의 인물(Z)을 활용하여 증인(X)의 증언 중 '진실된 부분'만을 걸러내어 사건의 진실(인과 효과)을 파악하는 것과 같다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **도구변수의 두 가지 핵심 조건 (IV's Superpowers)**\n",
        "좋은 도구변수 Z가 되기 위해서는, 아래의 두 가지 조건을 **반드시 '동시에'** 만족해야 한다.\n",
        "\n",
        "1.  **연관성 (Instrument Relevance)**\n",
        "    - **조건**: 도구변수(Z)는 내생변수(X)와 **강한 상관관계**가 있어야 한다. ($Cov(Z, X) \\neq 0$)\n",
        "    - **의미**: Z가 변할 때, X도 예측 가능하게 변해야 한다. 도구는 우리가 분석하려는 변수를 실제로 '움직일' 수 있어야 한다.\n",
        "    - **검증**: 이 조건은 **데이터로 검증이 가능**하다. 1단계 회귀분석(first stage)에서 Z가 X에 미치는 효과가 통계적으로 유의미한지 확인한다. (보통 F-statistic이 10 이상인지를 본다.)\n",
        "\n",
        "2.  **배제 제약 (The Exclusion Restriction)**\n",
        "    - **조건**: 도구변수(Z)는 **오직 내생변수(X)를 통해서만** 종속변수(Y)에 영향을 미쳐야 한다. Z가 Y로 가는 다른 경로가 있어서는 안 된다. ($Cov(Z, u) = 0$)\n",
        "    - **의미**: 이것이 IV 방법론의 가장 핵심적이고 강력한 가정이자, 가장 비판받기 쉬운 지점이다.\n",
        "    - **검증**: 이 조건은 **데이터로 증명하는 것이 불가능**하다. 연구자가 경제 이론과 논리적 근거를 통해 \"Z가 Y에 영향을 미칠 다른 경로가 왜 없는지\"를 매우 설득력 있게 주장해야만 한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **IV의 작동 원리: 2단계 최소자승법 (2SLS)**\n",
        "IV는 보통 2단계 최소자승법(2-Stage Least Squares)이라는 과정을 통해 효과를 추정한다.\n",
        "\n",
        "1.  **1단계 (First Stage): X '정화'시키기**\n",
        "    - 내생변수 X를 종속변수로, 도구변수 Z를 독립변수로 하여 OLS 회귀분석을 실행한다.\n",
        "        $$ X_i = \\pi_0 + \\pi_1 Z_i + \\nu_i $$\n",
        "    - 이 회귀식에서 X의 **예측값($\\hat{X}_i$)**을 구한다.\n",
        "    - **직관적 의미**: 이 예측값 $\\hat{X}_i$는, X의 전체 움직임 중에서 **오직 '깨끗한' 도구변수 Z에 의해서만 설명되는 부분**이다. 즉, 원래 X에 묻어있던 오염(OVB의 원인)을 걸러내고, Z와 관련된 '순수한' 부분만 추출한 것이다.\n",
        "\n",
        "2.  **2단계 (Second Stage): '정화된' X로 효과 추정하기**\n",
        "    - 원래의 회귀식에서 오염된 X 대신, 1단계에서 구한 **'정화된' 예측값 $\\hat{X}_i$를 독립변수로** 사용하여 OLS 회귀분석을 실행한다.\n",
        "        $$ Y_i = \\beta_0 + \\beta_1 \\hat{X}_i + \\epsilon_i $$\n",
        "    - 여기서 얻은 **$\\hat{\\beta}_1$이 바로 우리가 찾고 싶었던 X가 Y에 미치는 인과 효과의 추정치(IV estimator)**이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **고전적 예시: 교육의 수익률**\n",
        "\n",
        "- **연구 질문**: 교육 수준($X$)이 임금($Y$)에 미치는 영향은?\n",
        "- **문제**: 교육(X)은 '능력'($u$에 포함)과 관련이 있어 내생성을 갖는다.\n",
        "- **도구변수(Z) 후보**: \"자신이 태어난 지역과 가장 가까운 4년제 대학까지의 **거리**\"\n",
        "- **두 조건 확인**:\n",
        "    1.  **연관성 ($Z \\rightarrow X$)**: 대학과의 거리가 교육 수준에 영향을 주는가? 그렇다. 대학이 집 가까이 있으면 진학할 확률이 높아지는 경향이 있다. (데이터로 검증 가능)\n",
        "    2.  **배제 제약 ($Z \\not\\rightarrow u \\rightarrow Y$)**: 대학과의 거리가, 교육 수준을 통하는 경로 외에, 다른 경로로 임금에 영향을 주는가? 이것이 핵심 가정이다. \"대학과의 거리는 개인의 '타고난 능력'이나 '성실함' 등과는 아무런 관련이 없다\"고 주장해야 한다. (이 주장의 타당성에 대해 수많은 토론이 있을 수 있다.)"
      ],
      "metadata": {
        "id": "BhGGZc_0O-Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. 고정효과 모형 (Fixed Effects Model)\n",
        "### - 패널데이터를 이용한 OVB 해결의 핵심 -\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 누락 변수 편향(OVB)의 가장 큰 원인 중 하나는 개인, 회사, 국가 등이 가진 **'관찰되지 않고, 시간에 따라 잘 변하지 않는 고유한 특성'** 때문이다. (예: 개인의 타고난 능력, 성실함)\n",
        "- 패널데이터는 동일한 개체를 여러 시간에 걸쳐 추적하므로, 이 '변하지 않는 특성'의 영향력을 **수학적으로 완벽하게 제거**할 수 있다.\n",
        "- 고정효과 모형은 데이터의 **'그룹 간 차이(between-group variation)'**는 과감히 무시하고, 오직 **'각 그룹 내에서의 시간적 변화(within-group variation)'**에만 집중하여 OVB 문제를 해결한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **작동 원리: 'Within' 변환 (또는 'De-meaning')**\n",
        "1.  **개체별 평균 계산**: 모든 개체($i$)에 대해, 모든 변수들의 **시간에 걸친 평균**($\\bar{Y}\\_{i}$, $\\bar{X}\\_{i}$)을 각각 계산한다.\n",
        "2.  **평균 빼주기 (De-meaning)**: 모든 관측치에서, 자신이 속한 개체의 '개체별 평균'을 빼준다.\n",
        "3.  **변환된 데이터로 OLS 실행**: 이렇게 변환된 데이터들을 가지고 OLS를 실행한다.\n",
        "\n",
        "- **Within 변환의 마법**: '타고난 능력'처럼 시간에 따라 변하지 않는 변수들은, 각 시점의 값과 개체별 평균값이 동일하다. 따라서 **평균을 빼주는 순간 그 값이 정확히 '0'이 되어, 회귀식에서 완벽하게 사라진다.**\n",
        "\n",
        "<br>\n",
        "\n",
        "### **회귀분석 모형**\n",
        "고정효과 모형은 수식으로 두 가지 방식으로 표현될 수 있으며, 결과는 동일하다.\n",
        "\n",
        "1.  **개체 더미 변수 모형 (Entity Dummy Model)**:\n",
        "    $$\n",
        "    Y\\_{it} = \\beta\\_{1}X\\_{it} + \\alpha\\_{i} + u\\_{it}\n",
        "    $$\n",
        "    - 여기서 $\\alpha\\_{i}$는 각 개체 $i$의 모든 고유한 특성을 흡수하는 **'개체별 고정효과(fixed effect)'**를 의미한다.\n",
        "\n",
        "2.  **Within 변환 모형**:\n",
        "    $$\n",
        "    (Y\\_{it} - \\bar{Y}\\_{i}) = \\beta\\_{1}(X\\_{it} - \\bar{X}\\_{i}) + (u\\_{it} - \\bar{u}\\_{i})\n",
        "    $$\n",
        "    - 실제 통계 프로그램은 계산의 효율성을 위해 이 'Within 변환' 방식을 내부적으로 사용한다. $\\beta\\_{1}$의 추정치는 두 방식에서 동일하다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점과 한계**\n",
        "\n",
        "- **장점**:\n",
        "    - **강력한 OVB 통제**: 시간에 따라 변하지 않는 모든 관찰 불가능한 요인들을 통제할 수 있어, 매우 신뢰도 높은 방법이다.\n",
        "\n",
        "- **한계**:\n",
        "    - **시간 불변 변수 분석 불가**: Within 변환 과정에서 '성별', '인종' 등 시간에 따라 변하지 않는 변수들은 모두 사라지므로, **이러한 변수들의 효과 자체를 추정할 수 없다.**\n",
        "    - **측정 오차 문제에 민감**: 변수에 측정 오차가 있을 경우, 그 영향이 일반 OLS보다 더 크게 증폭될 수 있다."
      ],
      "metadata": {
        "id": "C2qcFuaSsyK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. 합성 통제법 (Synthetic Control Method, SCM)\n",
        "### - 최적의 비교 대상을 '만들어내는' 방법 -\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 특정 정책이나 사건의 영향을 받은 단일 개체(예: 특정 국가, 도시, 회사 하나)의 효과를 분석하고 싶을 때, **가장 이상적인 비교 대상을 데이터로부터 '합성'하여 만들어내는 방법.**\n",
        "- 어떤 단일 통제 집단(a single control unit)도 완벽한 비교 대상이 될 수 없다는 문제의식에서 출발한다. (예: \"서독 통일의 경제적 효과\"를 볼 때, 비교 대상으로 프랑스? 영국? 어떤 나라도 완벽한 대조군이 될 수 없다.)\n",
        "- SCM은 통제 집단 후보군(donor pool)에 속한 여러 개체들에 **적절한 가중치(weights)를 부여하고 조합**하여, 정책이 시행되기 전까지 처치 집단과 **거의 똑같은 '쌍둥이' 또는 '도플갱어'를 만들어낸다.**\n",
        "- 정책 시행 후, 실제 처치 집단의 결과와 '합성된 통제 집단(synthetic control)'의 결과를 비교하여 그 차이를 정책의 인과 효과로 추정한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **언제 SCM이 필요한가?: 비교사례연구 (Comparative Case Study)**\n",
        "- 처치가 **단 하나의 거시적인 단위(aggregate unit)**에 적용되었을 때 가장 유용하다.\n",
        "- 예시:\n",
        "    - 특정 국가에만 도입된 정책의 효과\n",
        "    - 특정 주(state)에만 도입된 법안의 효과\n",
        "    - 특정 회사에만 발생한 CEO 교체의 효과\n",
        "- 기존의 DID 방법론을 적용하기에는, 공통 추세 가정을 만족하는 단일 통제 집단을 찾기 어려울 때 강력한 대안이 된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **작동 원리: 최적의 가중치(weights) 찾기**\n",
        "SCM의 핵심은 '어떻게 최적의 가중치를 찾아내는가'에 있다.\n",
        "\n",
        "1.  **'훈련' 기간 설정**: 정책이 시행되기 **이전(pre-treatment) 기간**을 '훈련' 기간으로 설정한다.\n",
        "2.  **가중치 최적화**: 훈련 기간 동안, 처치 집단의 결과 변수(Y) 및 기타 주요 예측 변수(X)들의 **과거 경로를 가장 잘 모방하는 통제 집단들의 가중치 조합**을 데이터 기반 알고리즘을 통해 찾아낸다. 이 가중치는 0 이상이어야 하고, 모두 더하면 1이 된다.\n",
        "3.  **'반사실적 가상' 생성**: 이렇게 찾아낸 최적의 가중치를, 정책 시행 **이후(post-treatment) 기간**의 통제 집단들에게 그대로 적용한다. 이렇게 만들어진 가상의 그룹이 바로 '합성 통제 집단'이다. 이 합성 통제 집단의 경로는 **\"만약 처치 집단에 정책이 없었더라면 나타났을 가상의 결과(counterfactual)\"**를 의미한다.\n",
        "4.  **효과 측정**: 정책 시행 이후 기간 동안, **실제 처치 집단의 경로**와 **합성 통제 집단의 경로** 사이의 '격차(gap)'를 측정한다. 이 격차가 바로 정책의 인과 효과이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **고전적 예시: 캘리포니아 금연법 (Abadie, Diamond, & Hainmueller 2010)**\n",
        "- **연구 질문**: 1988년 캘리포니아에서 대규모 금연 캠페인(Proposition 99)이 담배 소비량에 미친 영향은?\n",
        "- **문제**: 캘리포니아는 매우 크고 독특한 주라서, 어떤 단일 주(state)도 좋은 통제 집단이 되기 어렵다.\n",
        "- **SCM의 해법**: 담배 소비량이 캘리포니아와 비슷했던 다른 주(state)들을 '통제 집단 후보군(donor pool)'으로 설정하고, SCM 알고리즘을 통해 최적의 가중치를 찾아 '합성 캘리포니아(Synthetic California)'를 만든다.\n",
        "- **결과**: 정책 시행 전까지 실제 캘리포니아와 합성 캘리포니아의 1인당 담배 소비량은 거의 똑같이 움직였다. 하지만 정책 시행 후, 실제 캘리포니아의 담배 소비량이 합성 캘리포니아보다 훨씬 더 급격하게 감소하는 것이 나타났다. 이 두 경로 사이의 격차가 바로 금연법의 효과가 된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점과 한계**\n",
        "\n",
        "- **장점**:\n",
        "    - **투명성**: 연구자가 자의적으로 통제 집단을 선택하는 것을 방지하고, 데이터 기반으로 최적의 비교 대상을 구성하는 과정을 투명하게 보여준다.\n",
        "    - **직관적인 시각화**: 실제 그룹과 합성 그룹의 경로를 그래프로 보여주는 것만으로도 매우 설득력 있고 이해하기 쉬운 결과를 제시할 수 있다.\n",
        "    - **내장된 위약 검사 (Placebo Test)**: 정책 시행 전 기간 동안 두 경로가 얼마나 잘 일치하는지 자체가 모델의 신뢰도를 보여주는 척도가 된다.\n",
        "\n",
        "- **한계**:\n",
        "    - **긴 사전 기간 데이터 필요**: 신뢰도 높은 가중치를 찾기 위해서는 정책 시행 전의 충분히 긴 시계열 데이터가 필요하다.\n",
        "    - **볼록 껍질(Convex Hull) 문제**: 처치 집단이 후보군 중 매우 극단적인 특성을 가질 경우, 좋은 합성 통제 집단을 만들기 어려울 수 있다.\n",
        "    - **통계적 추론의 복잡성**: p-value와 같은 통계적 유의성을 계산하는 것이 OLS보다 복잡하며, 보통 위약 검사(placebo test)와 같은 별도의 절차를 통해 강건성을 확인한다."
      ],
      "metadata": {
        "id": "LHP6aHqJwGY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. 이중 강건 추정법 (Doubly Robust Estimation, DRE)\n",
        "### - 두 번의 기회: 더 튼튼한 인과 효과 추정 -\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 관찰 데이터에서 누락 변수 편향(OVB)을 통제하고 인과 효과를 추정하려는 두 가지 대표적인 접근법이 있다.\n",
        "    1.  **결과 모델링 (Outcome Modeling)**: 결과(Y)가 처치(D)와 통제변수(X)에 의해 어떻게 결정되는지 직접 모델링하는 방식. (예: $Y \\sim D + X + X^2 \\dots$)\n",
        "    2.  **처치 모델링 (Treatment Modeling)**: 누가 처치(D)를 받는지 그 '선택 과정'을 직접 모델링하는 방식. (예: 성향점수(Propensity Score) 매칭)\n",
        "- 이 두 접근법은 각각 자신의 모델이 '정확하게' 명시되었다고 가정할 때만 편향 없는 결과를 준다. 즉, 둘 중 하나라도 모델 설정이 틀리면 추정치가 왜곡될 위험이 있다.\n",
        "- **이중 강건 추정법(DRE)**은 이 **두 가지 접근법을 하나의 추정식 안에 교묘하게 결합**하여, 둘 중 **'어느 하나만 맞아도'** 인과 효과를 올바르게 추정해주는 매우 '튼튼한(robust)' 속성을 갖는 방법론이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **직관적 이해: 편향을 막는 두 명의 경비원**\n",
        "인과 효과 추정치를 편향으로부터 지키는 '두 명의 경비원'이 있다고 상상해보자.\n",
        "\n",
        "- **경비원 1 (결과 모델)**: 회귀분석처럼, 통제변수(X)를 이용해 편향을 직접적으로 빼내서(통제해서) 결과를 보호한다. 이 경비원은 'Y가 어떻게 결정되는지'에 대한 정확한 정보를 가지고 있어야 임무를 완수할 수 있다.\n",
        "- **경비원 2 (처치 모델 / 성향점수)**: 성향점수 재가중(IPW)처럼, 처치 집단과 유사한 통제 집단에 가중치를 부여하여 데이터를 '실험(RCT)과 유사한 상태'로 만들어 결과를 보호한다. 이 경비원은 '누가 D=1이 되는지'에 대한 정확한 정보를 가지고 있어야 임무를 완수할 수 있다.\n",
        "\n",
        "**이중 강건 추정법(DRE)은 이 두 경비원을 동시에 배치하는 것과 같다.** 만약 경비원 1이 임무에 실패하더라도(결과 모델이 틀림), 경비원 2가 데이터를 잘 재조정해주어 편향을 막아준다. 반대로 경비원 2가 임무에 실패하더라도(처치 모델이 틀림), 경비원 1이 편향을 직접 잘 빼내주어 결과를 보호한다. **즉, 둘 중 한 명만 제대로 일하면 최종 결과는 안전하게 지켜진다.** 이것이 바로 '이중(doubly)'으로 '강건하다(robust)'는 의미이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **이중 강건 추정량의 구조 (AIPW 예시)**\n",
        "가장 대표적인 이중 강건 추정량은 '보강된 역확률 가중치(Augmented Inverse Propensity Weighting, AIPW)' 추정량이다. 수식은 매우 복잡해 보이지만, 그 구조를 이해하는 것이 중요하다.\n",
        "\n",
        "1.  **1단계**: **처치 모델**을 만든다. 통제변수 X를 이용해 각 개체가 처치를 받을 확률, 즉 성향점수($\\hat{p}(X_i)$)를 추정한다.\n",
        "2.  **2단계**: **결과 모델**을 만든다. 통제변수 X를 이용해, ①처치를 받았을 경우의 예상 결과($\\hat{\\mu}_1(X_i)$)와 ②처치를 받지 않았을 경우의 예상 결과($\\hat{\\mu}_0(X_i)$)를 각각 추정한다.\n",
        "3.  **3단계**: 이 재료들을 다음의 결합 공식에 넣어 최종적인 평균 처치 효과(ATE)를 계산한다.\n",
        "    - 이 공식은 기본적으로 **'성향점수 가중치(IPW) 부분'**과 **'결과 모델 기반의 보정항(augmentation term) 부분'**으로 구성되어 있다. 바로 이 '보정항'이 이중 강건 속성을 만들어내는 핵심 장치이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **머신러닝과의 연결: DML의 이론적 기초**\n",
        "- **DRE의 한계**: \"두 번의 기회\"는 훌륭하지만, 여전히 연구자가 OLS나 로짓 회귀분석 같은 전통적인 방법으로 결과 모델이나 처치 모델 중 하나를 '올바르게' 설정해야 한다는 부담이 남는다. 만약 현실이 너무 복잡해서 두 모델 모두를 잘못 설정하면 DRE도 실패한다.\n",
        "- **머신러닝의 역할**: 여기서 머신러닝이 등장한다. 랜덤 포레스트, 라쏘, 부스팅 같은 머신러닝 알고리즘은 복잡하고 비선형적인 관계를 매우 유연하게 예측하는 데 탁월하다.\n",
        "- **아이디어**: DRE 공식의 1단계(처치 모델)와 2단계(결과 모델)를 만들 때, 전통적인 통계 모형 대신 **머신러닝을 사용하면 어떨까?**\n",
        "- **DML로의 발전**: **이중/편향제거 머신러닝(Double/Debiased Machine Learning, DML)**은 바로 이 아이디어를 통계적으로 엄밀하게 구현한 최신 방법론이다. DML은 DRE의 원리를 기반으로, 교차적합(cross-fitting)과 같은 추가적인 장치를 통해 머신러닝 '블랙박스' 모델을 사용하면서도 최종적인 인과 효과($\\tau$)를 편향 없이, 그리고 통계적 추론(가설 검정)이 가능하도록 만들어준다.\n",
        "\n",
        "따라서, 이중 강건 추정법은 **전통적 인과추론의 정점이자 머신러닝 인과추론으로 나아가는 가장 중요한 이론적 초석**이라고 할 수 있다."
      ],
      "metadata": {
        "id": "VB9SQUphxYhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 보론: 로짓과 프로빗 모형 (Appendix: Logit and Probit Models)\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 종속변수($Y$)가 **'예/아니오', '성공/실패' 등 0 또는 1의 값만 갖는 이진(binary) 변수**일 때 사용하는 회귀분석 도구.\n",
        "- OLS는 $Y$가 연속적인 값(임금, 성적 등)을 가질 때 사용하지만, $Y$가 0/1일 때 OLS를 쓰면 예측값이 0과 1을 벗어나는 등 여러 통계적 문제가 발생한다.\n",
        "- 로짓/프로빗 모형은 S자 형태의 비선형 함수(로지스틱 함수, 정규분포 누적함수)를 사용하여, 예측 결과가 항상 **0과 1 사이의 '확률'**로 나오도록 만들어준다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **주요 사용처**\n",
        "\n",
        "1.  **분류 문제 (Classification Problems)**: 머신러닝의 '예측' 영역에서, 특정 개체가 0과 1 중 어느 그룹에 속할지를 예측(분류)할 때 널리 사용된다.\n",
        "    - 예시: \"고객의 나이, 소득, 방문 횟수(X)를 보고, 이 고객이 1년 내에 이탈할지(Y=1) 안 할지(Y=0) 확률을 예측\"\n",
        "\n",
        "2.  **처치 모델링 (Treatment Modeling)**: **인과추론에서 매우 중요!** '이중 강건 추정법(DRE)'에서 설명했듯이, 특정 개체가 처치를 받을 확률, 즉 **성향점수(Propensity Score)를 추정**할 때 핵심적으로 사용된다.\n",
        "    - 예시: \"개인의 소득, 학력, 거주지(X)를 보고, 이 사람이 직업 훈련 프로그램에 참여할(D=1) 확률을 계산\"\n",
        "\n",
        "3.  **인과추론의 계산 도구**: DID, RDD, IV 등 인과추론 '요리법'을 사용했는데, 마침 종속변수가 0/1 변수인 경우, 최종 계산 단계에서 OLS 대신 로짓/프로빗을 '조리도구'로 사용한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **결론**\n",
        "- 로짓/프로빗은 그 자체로 OVB를 해결해주는 인과추론 방법론이 **아니다.**\n",
        "- OLS와 마찬가지로, **주어진 데이터를 가장 잘 설명하는 모델을 찾는 '분석 도구'**이다.\n",
        "- 다만, **종속변수가 0/1일 때 OLS를 대체**하며, 특히 성향점수 추정 등을 통해 다른 인과추론 방법론들을 보조하는 데 매우 중요한 역할을 한다."
      ],
      "metadata": {
        "id": "odPYcpGHy7La"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 보론 2: 일반화 최소자승법 (GLS)과 OLS의 관계\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- OLS는 모든 관측치(data point)를 똑같이 중요하게 취급하여 잔차 제곱합을 최소화한다.\n",
        "- 하지만 오차항에 **이분산성(Heteroskedasticity)**이나 **계열상관(Autocorrelation)** 문제가 있다면, 어떤 관측치는 다른 관측치보다 더 많은 '노이즈(noise)'를 담고 있어 신뢰도가 떨어진다.\n",
        "- **GLS(Generalized Least Squares)**는 이러한 '신뢰도가 낮은' 관측치에는 **낮은 가중치**를, '신뢰도가 높은' 관측치에는 **높은 가중치**를 부여하여, OLS보다 더 효율적이고 정밀한(efficient) 추정치를 찾아내는 방법이다.\n",
        "- 대표적인 GLS의 한 종류가 이분산성 문제를 다루는 **가중 최소자승법(Weighted Least Squares, WLS)**이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **GLS vs. 강건 표준오차: 무엇이 다른가?**\n",
        "\n",
        "이 둘의 차이를 이해하는 것이 매우 중요합니다. 고장 난 자동차를 운전하는 상황에 비유할 수 있습니다.\n",
        "\n",
        "- **OLS + 강건 표준오차 (문제를 '인정'하고 대처하는 방식)**:\n",
        "    - 자동차의 핸들(표준오차)이 약간 떨리고 헐겁다는 것을 알지만, 일단 운전(계수 추정)은 그대로 한다. 대신, 핸들이 떨린다는 사실을 감안하여 **운전 습관을 보수적으로 바꾸고(p-value를 더 엄격하게 해석) 목적지에 안전하게 도착**한다.\n",
        "    - **$\\hat{\\beta}$ 계수 자체는 OLS와 동일**하며, **표준오차만 사후에 보정**한다.\n",
        "\n",
        "- **GLS (문제를 '수리'하고 운전하는 방식)**:\n",
        "    - 자동차를 정비소로 가져가 **헐거운 핸들 자체를 완벽하게 수리**한다. 그 후에 편안하고 정밀하게 운전하여 목적지에 도착한다.\n",
        "    - 데이터 자체를 변환하여 오차항의 문제를 없앤 뒤 회귀분식을 실행하므로, **$\\hat{\\beta}$ 계수 자체가 OLS와 달라지며, 이론적으로 가장 효율적인(분산이 가장 작은) 추정치**가 된다. (이를 **BLUE**: Best Linear Unbiased Estimator 라고 한다.)\n",
        "\n",
        "| 구분 | OLS + 강건 표준오차 | GLS / WLS |\n",
        "| :--- | :--- | :--- |\n",
        "| **목표** | **부정확한 '표준오차'를 수정** (Correcting Inference) | **비효율적인 '계수'를 개선** (Improving Efficiency) |\n",
        "| **$\\hat{\\beta}$ 계수**| OLS와 동일 | OLS와 다름 (더 효율적) |\n",
        "| **핵심 가정**| 오차항 구조에 대한 가정이 필요 없음 | **오차항의 분산/상관 구조를 정확히 알아야 함** |\n",
        "\n",
        "<br>\n",
        "\n",
        "### **왜 현대 응용미시에서는 강건 표준오차를 더 선호하는가?**\n",
        "이론적으로는 GLS가 더 우월해 보이지만, 현실의 응용미시경제학 연구(노동, 산업 등)에서는 OLS와 강건 표준오차(특히 군집 표준오차)의 조합이 압도적으로 많이 쓰입니다.\n",
        "\n",
        "그 이유는 GLS의 **치명적인 전제조건** 때문이다.\n",
        "\n",
        "> **\"GLS를 사용하려면, 오차항의 문제 구조(이분산성의 형태, 계열상관의 형태)를 연구자가 '정확히' 알고 있다는 가정이 필요하다.\"**\n",
        "\n",
        "- 예를 들어, WLS를 사용하려면 오차항의 분산이 '소득' 변수와 정확히 어떤 함수 관계(비례하는지, 제곱에 비례하는지 등)에 있는지를 알아야만 올바른 가중치를 부여할 수 있다.\n",
        "- 하지만 현실에서 우리는 그 정확한 형태를 **절대 알 수 없다.** 만약 연구자가 잘못된 형태로 추측하여 GLS를 적용하면(misspecification), 그 결과는 **OLS보다 훨씬 더 심각한 편향**을 가질 수 있다. 즉, '수리'를 잘못하면 차가 더 망가지는 것과 같다.\n",
        "\n",
        "반면, **강건 표준오차**는 \"나는 오차항의 문제 구조가 정확히 어떤 형태인지는 모르겠다. 하지만 그게 무엇이든 간에, 그 문제에 영향을 받지 않는 튼튼한 표준오차를 계산하겠다\"는, **훨씬 더 현실적이고 겸손한 접근법**이다.\n",
        "\n",
        "이러한 이유로, 연구의 '신뢰성'과 '강건성'을 중시하는 현대 인과추론 분석에서는, 약간의 효율성을 포기하더라도 더 적은 가정을 필요로 하는 **OLS + 강건 표준오-차 조합이 표준적인 분석 방법**으로 자리 잡게 되었다."
      ],
      "metadata": {
        "id": "6mP4o8ZxzRIR"
      }
    }
  ]
}