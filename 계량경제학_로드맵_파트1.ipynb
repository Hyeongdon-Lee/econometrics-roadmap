{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **파트 1: OLS 회귀분석의 원리와 응용**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 1. OLS (Ordinary Least Squares, 최소자승법)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 수많은 데이터 점들(산점도)이 흩어져 있을 때, 이 데이터들의 관계와 경향성을 가장 잘 대표하는 **하나의 직선(linear line)을 긋는 방법.**\n",
        "- 기본적으로 변수들 간의 **'평균적인 상관관계'**를 설명하는 데 사용된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **모형과 수식 (Model and Equation)**\n",
        "OLS는 우리가 관심 있는 변수들 사이의 관계를 다음과 같은 선형 방정식으로 가정합니다.\n",
        "\n",
        "$$Y_i = \\beta_0 + \\beta_1 X_i + u_i$$\n",
        "\n",
        "- $Y_i$ : **종속변수 (Dependent Variable)**. 우리가 설명하고 예측하고 싶은 결과 변수. (예: 개인 $i$의 임금)\n",
        "- $X_i$ : **독립변수 (Independent Variable)**. 결과($Y_i$)를 설명하는 데 사용되는 원인 변수. (예: 개인 $i$의 교육 연수)\n",
        "- $u_i$ : **오차항 (Error Term)**. $X_i$ 외에 $Y_i$에 영향을 미치는 모든 관찰되지 않은 요인들의 총합.\n",
        "- $\\beta_0$ : **상수항 (Intercept)**. $X_i$가 0일 때의 $Y_i$의 평균적인 값.\n",
        "- $\\beta_1$ : **기울기 계수 (Slope Coefficient)**. **우리가 가장 알고 싶은 값.** $X_i$가 1단위 변할 때, $Y_i$가 **평균적으로** 얼마나 변하는지를 나타냅니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **OLS의 목표 (Objective of OLS)**\n",
        "OLS는 실제 데이터 값($Y_i$)과, 직선이 예측하는 값($\\hat{Y}_i$) 사이의 **'오차(residual, 잔차)'를 최소화**하는 것을 목표로 합니다.\n",
        "\n",
        "구체적으로는, 각 데이터 포인트에서 발생하는 잔차($\\hat{u}_i = Y_i - \\hat{Y}_i$)를 **제곱해서 모두 더한 값**, 즉 **잔차 제곱합(Sum of Squared Residuals, SSR)**을 가장 작게 만드는 $\\hat{\\beta}_0$와 $\\hat{\\beta}_1$을 찾아냅니다.\n",
        "\n",
        "$$ \\min_{\\hat{\\beta}_0, \\hat{\\beta}_1} \\sum_{i=1}^{n} \\hat{u}_i^2 = \\min_{\\hat{\\beta}_0, \\hat{\\beta}_1} \\sum_{i=1}^{n} (Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i)^2 $$\n",
        "\n",
        "> (※ 잔차를 제곱하는 이유는 양수(+) 오차와 음수(-) 오차가 서로 상쇄되는 것을 막고, 큰 오차에 더 큰 페널티를 부여하기 위함입니다.)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **핵심 가정 (Key Assumption for Causality)**\n",
        "OLS 추정치 $\\hat{\\beta}_1$이 '상관관계'를 넘어 '인과관계'로 해석되기 위한 가장 중요한 가정은 **평균 독립 가정 (Zero Conditional Mean)** 입니다.\n",
        "\n",
        "$$ E(u_i | X_i) = 0 $$\n",
        "\n",
        "- **의미**: 독립변수 $X_i$의 값과 무관하게, 오차항 $u_i$의 평균은 항상 0이다.\n",
        "- **더 쉬운 설명**: $X_i$와 오차항 $u_i$는 서로 아무런 관련이 없다. 즉, '숨겨진 제3의 요인'이 없어야 한다.\n",
        "- **이 가정이 깨질 때**: **누락 변수 편향(OVB)**이 발생하며, $\\hat{\\beta}_1$은 인과 효과를 제대로 추정하지 못합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **해석의 예시**\n",
        "\n",
        "- **연구 질문**: \"교육 연수가 임금에 미치는 영향은?\"\n",
        "- **데이터**: 1000명의 성인에 대한 임금(월, 만원 단위)과 교육 연수(년) 데이터\n",
        "- **OLS 추정 결과 (가상)**:\n",
        "    $$ \\widehat{wage_i} = 50 + 10 \\times education_i $$\n",
        "\n",
        "- **해석**:\n",
        "    - **$\\hat{\\beta}_1 = 10$**: \"다른 모든 조건이 동일할 때, 교육 연수가 1년 증가하면 월 임금이 **평균적으로 10만 원 증가하는 상관관계**가 관찰된다.\"\n",
        "    - **인과관계 주장 불가 이유**: '타고난 능력'과 같이 교육과 임금 모두에 영향을 주는 변수가 존재할 가능성이 높아, 평균 독립 가정이 깨졌을 수 있기 때문이다."
      ],
      "metadata": {
        "id": "EE7neE2aszjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 누락 변수 편향 (Omitted Variable Bias, OVB)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 우리가 관심 있는 변수 X와 결과 Y의 관계를 분석할 때, 이 둘 모두에게 영향을 미치는 **'숨겨진 제3의 변수(Z)'**가 분석에서 빠지게 되면, X의 효과를 잘못 추정하게 되는 문제.\n",
        "- OLS가 이 숨겨진 변수(Z)의 효과를 엉뚱하게 X의 효과인 것처럼 착각하여, X의 영향력을 과대평가하거나 과소평가하게 만든다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **OVB의 발생 조건**\n",
        "누락 변수 편향은 아래의 **두 가지 조건이 '동시에' 충족될 때** 발생한다. 둘 중 하나라도 만족하지 않으면 OVB는 없다.\n",
        "\n",
        "1.  누락된 변수(Z)가 **종속변수(Y)에 영향을 미치는 변수**여야 한다. (즉, Z는 Y의 원인이다.)\n",
        "2.  누락된 변수(Z)가 회귀식에 포함된 **독립변수(X)와 상관관계**가 있어야 한다. (즉, Z와 X는 서로 관련이 있다.)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **편향의 방향과 크기 (The OVB Formula)**\n",
        "누락 변수 편향의 방향과 크기는 다음의 유명한 공식으로 표현할 수 있다.\n",
        "\n",
        "- **우리가 추정하고 싶은 '진짜' 세상의 모델:**\n",
        "    $$ Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 Z_i + e_i $$\n",
        "    (여기서 $\\beta_1$이 우리가 알고 싶은 X의 '진정한' 인과 효과이다.)\n",
        "\n",
        "- **데이터의 한계로 우리가 '실제로' 돌리는 모델:**\n",
        "    $$ Y_i = \\gamma_0 + \\gamma_1 X_i + u_i $$\n",
        "    (Z 변수를 누락했다.)\n",
        "\n",
        "이때, 우리가 얻게 될 추정치 $\\hat{\\gamma}_1$의 기댓값은 다음과 같다.\n",
        "\n",
        "$$ E[\\hat{\\gamma}_1] = \\beta_1 + \\beta_2 \\cdot \\delta_{XZ} $$\n",
        "\n",
        "- $E[\\hat{\\gamma}_1]$: 우리가 OLS로 추정한 X의 계수(우리의 결과값)\n",
        "- $\\beta_1$: 우리가 정말 알고 싶은 X의 순수한 효과(진짜 값)\n",
        "- **$\\beta_2 \\cdot \\delta_{XZ}$**: **이 부분이 바로 '편향(Bias)'이다.**\n",
        "\n",
        "    - $\\beta_2$: 누락된 변수 Z가 종속변수 Y에 미치는 영향. (조건 1)\n",
        "    - $\\delta_{XZ}$: 독립변수 X와 누락된 변수 Z 간의 상관관계. (조건 2)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **예시: 교육 - 임금 - 능력**\n",
        "\n",
        "OLS 파트에서 들었던 고전적인 예시를 통해 편향의 방향을 예측해보자.\n",
        "\n",
        "- **연구 질문**: 교육($X$)이 임금($Y$)에 미치는 영향($\\beta_1$)\n",
        "- **누락된 변수**: '타고난 능력'($Z$)\n",
        "- **분석**:\n",
        "    1.  **조건 1 확인 ($\\beta_2$의 부호)**: '능력'($Z$)이 '임금'($Y$)에 미치는 영향은?\n",
        "        - 당연히 양수(+)일 것이다. 능력이 높을수록 임금이 높다. ($\\beta_2 > 0$)\n",
        "    2.  **조건 2 확인 ($\\delta_{XZ}$의 부호)**: '교육'($X$)과 '능력'($Z$)의 상관관계는?\n",
        "        - 대체로 양수(+)일 것이다. 능력이 높은 사람이 교육도 더 많이 받는 경향이 있다. ($\\delta_{XZ} > 0$)\n",
        "- **편향의 방향 계산**:\n",
        "    $$ \\text{Bias} = \\beta_2 \\cdot \\delta_{XZ} = (+) \\times (+) = (+) $$\n",
        "- **결론**: 편향이 **양수(+)**이므로, 우리가 OLS로 추정한 교육의 효과($\\hat{\\gamma}_1$)는 실제 순수한 효과($\\beta_1$)보다 **더 크게(과대평가)** 나올 것이다.\n",
        "    $$ E[\\hat{\\gamma}_1] = \\beta_1 + (\\text{양수의 편향}) $$\n",
        "    (OLS는 '능력' 덕분에 올라간 임금까지 전부 '교육'의 공으로 잘못 돌리고 있는 것이다.)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XdW7w2-lt0gE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 가설 검정 (Hypothesis Testing)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 우리가 샘플 데이터로 분석한 결과(예: OLS로 추정한 계수)가 정말로 의미가 있는 것인지, 아니면 그냥 **'우연히' 그렇게 나온 결과인지**를 통계적으로 판단하는 과정.\n",
        "- \"이 약은 효과가 있다\"고 주장하려면, 약의 효과가 '0'이라는 증거가 없다는 것을 보여야 하는 재판과 같다. 즉, **\"효과가 없다\"는 주장을 먼저 세우고, 그 주장이 틀렸다는 것을 데이터로 증명**하는 방식을 사용한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **가설 검정의 주요 개념**\n",
        "\n",
        "1.  **귀무가설 (Null Hypothesis, $H_0$)**\n",
        "    - 우리가 기각(틀렸다고 증명)하고 싶은 주장. 보통 \"**효과가 없다**\"는 형태로 설정된다.\n",
        "    - 예시: \"교육은 임금에 아무런 영향을 주지 않는다.\"\n",
        "    - 수식: $$ H_0: \\beta_1 = 0 $$\n",
        "\n",
        "2.  **대립가설 (Alternative Hypothesis, $H_1$ or $H_A$)**\n",
        "    - 귀무가설이 기각될 때 우리가 받아들이게 되는 주장. 보통 \"**효과가 있다**\"는 형태로 설정된다.\n",
        "    - 예시: \"교육은 임금에 영향을 준다.\"\n",
        "    - 수식: $$ H_1: \\beta_1 \\neq 0 $$\n",
        "\n",
        "<br>\n",
        "\n",
        "### **판단의 도구: t-통계량과 p-value**\n",
        "\n",
        "우리가 얻은 데이터가 귀무가설을 기각할 만큼 충분히 강력한 증거를 담고 있는지 판단하기 위해 다음 두 가지 핵심 도구를 사용한다.\n",
        "\n",
        "1.  **t-통계량 (t-statistic)**\n",
        "    - **계산식**:\n",
        "        $$ t = \\frac{\\text{추정된 계수} - \\text{귀무가설 값}}{\\text{계수의 표준오차}} = \\frac{\\hat{\\beta}_1 - 0}{\\text{SE}(\\hat{\\beta}_1)} $$\n",
        "    - **직관적 의미**: 우리가 추정한 효과($\\hat{\\beta}_1$)가, 그 추정치가 갖는 불확실성/노이즈(표준오차)에 비해 **상대적으로 얼마나 큰지를 나타내는 값**. 즉, **'신호 대 잡음비'**와 같다. t-통계량의 절댓값이 클수록, 우리의 추정치가 0과는 확실히 구별된다는 의미이다.\n",
        "\n",
        "2.  **p-value (유의확률)**\n",
        "    - **정의**: **귀무가설이 사실이라고 가정했을 때(즉, 실제 효과가 0일 때)**, 우리가 현재 샘플에서 얻은 것과 같거나 더 극단적인 결과(t-통계량)가 '우연히' 관찰될 확률.\n",
        "    - **더 쉬운 설명**: \"**p-value가 작을수록, 우리의 결과가 '단순한 우연'일 가능성이 낮다**\"는 의미. p-value가 매우 작다면(예: 0.01), \"실제 효과가 없는데도 우연히 이런 결과가 나올 확률이 1%밖에 안 된다. 이건 우연이 아닐 것이다\"라고 생각할 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **의사결정 규칙: 유의수준**\n",
        "\n",
        "- **유의수준 (Significance Level, $\\alpha$)**\n",
        "    - 우리가 \"이 정도 확률보다 낮으면, 우연이라고 보기 어렵다\"고 판단하는 **기준점**.\n",
        "    - 사회과학에서는 보통 **5%(0.05)**를 기준으로 삼는다. 때로는 10%(0.10)나 1%(0.01)를 사용하기도 한다.\n",
        "\n",
        "- **판단 규칙**:\n",
        "    - **`p-value < α` (예: 0.05) 일 경우**:\n",
        "        - \"귀무가설을 **기각(reject)**한다.\"\n",
        "        - 결과가 **\"통계적으로 유의미하다(statistically significant)\"**고 말한다.\n",
        "        - 결론: X가 Y에 미치는 효과가 있다는 충분한 통계적 증거를 확보했다.\n",
        "    - **`p-value ≥ α` (예: 0.05) 일 경우**:\n",
        "        - \"귀무가설을 **기각하지 못한다(fail to reject)**.\"\n",
        "        - 결과가 **\"통계적으로 유의미하지 않다(not statistically significant)\"**고 말한다.\n",
        "        - 결론: X가 Y에 미치는 효과가 있다는 통계적 증거를 찾지 못했다. (주의: 효과가 '0'이라고 증명한 것은 아니다!)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **예시: OLS 결과표 다시보기**\n",
        "\n",
        "- **OLS 추정 결과**: 교육의 계수($\\hat{\\beta}_1$) = 10,  표준오차(SE) = 2\n",
        "- **가설 설정**:\n",
        "    - $H_0: \\beta_1 = 0$ (교육은 효과 없다)\n",
        "    - $H_1: \\beta_1 \\neq 0$ (교육은 효과 있다)\n",
        "- **t-통계량 계산**:\n",
        "    - $t = (10 - 0) / 2 = 5$\n",
        "    - (추정된 효과가 불확실성의 5배 크기라는 의미로, 매우 크다.)\n",
        "- **p-value 및 판단**:\n",
        "    - t-통계량이 5일 때의 p-value는 거의 0에 가깝다 (예: 0.00001).\n",
        "    - 이 p-value(0.00001)는 우리가 설정한 유의수준 5%(0.05)보다 훨씬 작다.\n",
        "- **최종 해석**:\n",
        "    - 귀무가설을 기각한다. \"교육이 임금에 미치는 영향은 5% 유의수준에서 **통계적으로 유의미하다**.\""
      ],
      "metadata": {
        "id": "tIVs6HGJvG6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 강건 표준오차 (Robust Standard Errors)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- OLS로 계산된 표준오차(Standard Error)는 **\"오차항($u_i$)이 아주 이상적인(깔끔한) 형태를 가질 것\"**이라는 여러 고전적 가정들 위에서 계산된다.\n",
        "- 하지만 현실 세계의 데이터는 대부분 이상적이지 않으므로, 이 가정들이 깨지는 경우가 빈번하다.\n",
        "- 가정이 깨지면, 우리가 계산한 표준오차가 **잘못된(biased) 값**이 되고, 결국 **t-통계량과 p-value를 믿을 수 없게 되는** 심각한 문제가 발생한다.\n",
        "- **강건 표준오차**는 이러한 고전적 가정이 깨지더라도, **여전히 신뢰할 수 있는(robust) 표준오차를 계산해주는 방법**이다. 즉, 우리의 가설 검정을 더 '튼튼하게' 만들어주는 안전장치이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **무엇이 문제인가?: 깨지기 쉬운 고전적 가정들**\n",
        "\n",
        "표준오차 계산에 영향을 미치는 가장 대표적인 두 가지 가정은 다음과 같다.\n",
        "\n",
        "1.  **동분산성 (Homoskedasticity)**\n",
        "    - **가정**: 오차항($u_i$)의 분산이 독립변수($X_i$)의 값에 관계없이 **일정하다**.\n",
        "    - **현실 (위반)**: **이분산성 (Heteroskedasticity)**. $X_i$의 값에 따라 오차항의 분산이 달라지는 경우가 훨씬 흔하다.\n",
        "    - **예시**: '소득(X)과 소비(Y)'의 관계. 저소득층은 소득의 대부분을 필수재에 소비하므로 소비 패턴이 비교적 일정하다(오차의 분산이 작다). 반면, 고소득층은 소비 선택의 폭이 매우 넓어, 소비 패턴이 매우 다양하다(오차의 분산이 크다).\n",
        "\n",
        "2.  **오차항의 독립성 (No Autocorrelation)**\n",
        "    - **가정**: 각각의 오차항($u_i$)들은 서로 아무런 관련이 없이 독립적이다.\n",
        "    - **현실 (위반)**: **계열상관 (Serial Correlation) / 군집 (Clustering)**. 특정 그룹 내의 데이터들은 서로 연관되어 있는 경우가 많다.\n",
        "    - **예시**: '한 반의 학생들 성적' 데이터. 같은 반 학생들은 동일한 선생님, 수업 환경, 친구들을 공유하므로, 성적의 오차항들이 서로 독립적이라고 보기 어렵다. 즉, 데이터가 '반'이라는 단위로 **군집(cluster)**되어 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **해결책: 두 종류의 강건 표준오차**\n",
        "\n",
        "이러한 문제들을 해결하기 위해, 현대 계량경제학에서는 주로 두 가지 강건 표준오차를 사용한다.\n",
        "\n",
        "1.  **White 표준오차 (White Standard Errors)**\n",
        "    - **목적**: **이분산성(Heteroskedasticity)** 문제를 해결하기 위해 고안되었다.\n",
        "    - **별명**: '이분산성-강건 표준오차 (Heteroskedasticity-Robust Standard Errors)'라고도 불린다.\n",
        "    - **언제 사용하는가**: 오차항의 분산이 일정하지 않을 것이라는 의심이 들 때 사용한다. 사실상 대부분의 사회과학 데이터는 잠재적 이분산성 문제를 가지고 있다.\n",
        "\n",
        "2.  **군집 표준오차 (Clustered Standard Errors)**\n",
        "    - **목적**: **군집(Clustering)** 문제를 해결하기 위해 고안되었다.\n",
        "    - **작동 방식**: 데이터를 특정 그룹(cluster, 예: 지역, 학교, 회사, 개인)으로 묶고, **그룹 내에서는 오차항들이 서로 상관관계가 있을 수 있다는 점을 감안**하여 표준오차를 계산한다. 그룹 간에는 독립적이라고 가정한다.\n",
        "    - **언제 사용하는가**: 데이터가 명확한 그룹 구조를 가질 때 사용한다. (예: 여러 도시의 시민들 데이터 → '도시'를 기준으로 군집, 한 회사의 여러 연도 재무 데이터 → '회사'를 기준으로 군집). 패널 데이터(Panel data) 분석에서는 거의 필수로 사용된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **실용적인 결론 (Rule of Thumb)**\n",
        "- 현대의 실증 분석에서는 특별한 이론적 이유가 없는 한, **거의 항상 강건 표준오차를 사용한다.**\n",
        "- 특히 데이터가 그룹 구조를 가질 경우(대부분의 경우), **군집 표준오차(Clustered Standard Errors)를 사용하는 것이 표준(standard)**으로 여겨진다.\n",
        "- 일반 OLS 표준오차 대신 강건 표준오차를 사용하는 것은, 분석의 신뢰도를 높이는 매우 중요한 과정이며, 연구자의 신중함을 보여주는 지표이다."
      ],
      "metadata": {
        "id": "NqVw1kh97Tyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 다중공선성 (Multicollinearity)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 회귀분석에 사용된 **독립변수들(X)끼리 서로 너무 강하게 연관되어 있는** 문제.\n",
        "- 예를 들어, '교육 연수($X_1$)'와 '상위 10% 대학 졸업 여부($X_2$)'를 모두 독립변수로 사용하면, 이 둘은 매우 높은 상관관계를 가질 것이다.\n",
        "- OLS 모델이 Y에 대한 공통된 설명력을 가진 X 변수들 사이에서, **\"이 효과가 정확히 누구의 공로인지\"** 헷갈리게 되는 상황이다. 마치 쌍둥이 용의자 두 명을 앞에 두고 누가 범인인지 특정하기 어려워하는 것과 같다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **무엇이 문제인가?: 부정확해지는 표준오차**\n",
        "다중공선성이 존재할 때 발생하는 가장 핵심적인 문제는, 각 변수의 **표준오차(standard error)가 매우 커지는** 현상이다.\n",
        "\n",
        "이로 인해 다음과 같은 연쇄 반응이 일어난다.\n",
        "\n",
        "1.  표준오차(SE)가 비정상적으로 커진다.\n",
        "2.  t-통계량($t = \\hat{\\beta} / \\text{SE}$)의 절댓값이 작아진다.\n",
        "3.  p-value가 커진다.\n",
        "4.  **최종 결과**: 실제로는 Y에 영향을 미치는 변수임에도 불구하고, p-value가 커져서 **\"통계적으로 유의미하지 않다\"**는 결론을 내릴 위험이 커진다.\n",
        "\n",
        "> **중요한 점**: 다중공선성은 개별 변수($\\hat{\\beta_1}$, $\\hat{\\beta_2}$ 등)의 효과를 정확히 분리해내는 것을 방해할 뿐, 모델 전체의 예측력(예: R-squared) 자체를 낮추지는 않는 경우가 많다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **다중공선성의 종류**\n",
        "\n",
        "1.  **완벽한 다중공선성 (Perfect Multicollinearity)**\n",
        "    - **정의**: 하나의 독립변수가 다른 독립변수(들)의 완벽한 선형 조합으로 표현될 수 있는 경우.\n",
        "    - **예시 (더미 변수 함정, Dummy Variable Trap)**: '성별' 변수를 만들 때, '남성 더미($D_{male}$)'와 '여성 더미($D_{female}$)'를 **모두** 회귀식에 포함시키는 경우. $D_{male} + D_{female} = 1$이 되어 상수항과 완벽한 선형 관계를 이루게 된다.\n",
        "    - **결과**: OLS 추정 자체가 수학적으로 **불가능**하다. 대부분의 통계 프로그램은 이 경우 자동으로 변수 중 하나를 제외하고 분석을 수행하거나 에러 메시지를 출력한다. **발견하고 해결하기 쉽다.**\n",
        "\n",
        "2.  **불완전한 다중공선성 (Imperfect Multicollinearity)**\n",
        "    - **정의**: 독립변수들 간의 상관관계가 매우 높지만, 완벽하지는 않은 경우.\n",
        "    - **예시**: '개인의 키($X_1$)'와 '몸무게($X_2$)'를 모두 사용하여 '달리기 속도(Y)'를 예측하는 경우. 키와 몸무게는 매우 높은 양의 상관관계를 갖는다.\n",
        "    - **결과**: OLS 추정은 가능하지만, 위에서 설명한 대로 **표준오차가 커져** 키와 몸무게 각각의 '순수한' 영향력을 정확히 추정하기 어려워진다. **현실에서 마주하는 더 흔하고 미묘한 문제**이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **진단 및 해결책**\n",
        "\n",
        "- **진단**:\n",
        "    - 독립변수들 간의 **상관관계 행렬(correlation matrix)**을 확인하여 0.8~0.9 이상의 높은 상관관계가 있는지 본다.\n",
        "    - **VIF (Variance Inflation Factor, 분산 팽창 요인)** 값을 확인한다. VIF는 각 변수가 다른 변수들에 의해 얼마나 잘 설명되는지를 나타내는 지표로, **보통 VIF가 10을 넘으면 다중공선성을 의심**한다.\n",
        "\n",
        "- **해결책**:\n",
        "    1.  **변수 제거**: 상관관계가 매우 높은 변수들 중, 이론적으로 덜 중요하거나 측정 오차가 클 것으로 예상되는 변수 하나를 제거한다.\n",
        "    2.  **변수 결합**: 매우 유사한 개념을 측정하는 변수들을 합쳐 새로운 하나의 변수(예: 지수)로 만든다. (예: '아버지 교육수준'과 '어머니 교육수준'을 합쳐 '부모 교육수준'으로)\n",
        "    3.  **데이터 추가 수집**: 더 많은 데이터를 확보하면 표준오차를 줄이는 데 도움이 될 수 있다.\n",
        "    4.  **그대로 두기**: 만약 다중공선성이 높은 변수들이 우리의 핵심 관심 변수가 아니라, 단순히 결과에 영향을 미칠 다른 요인들을 통제하기 위해 넣은 **통제변수(control variables)**일 뿐이라면, 굳이 해결하지 않아도 큰 문제가 되지 않을 수 있다."
      ],
      "metadata": {
        "id": "i88_grPqM1j6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. OLS 응용 기술: 더미 변수, 비선형 관계, 상호작용 항\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 현실 세계는 단순한 직선 관계로만 이루어져 있지 않다. OLS 모델이 현실을 더 잘 반영하도록 **유연성(flexibility)**을 부여하는 세 가지 핵심적인 기술.\n",
        "- **더미 변수**: '숫자'가 아닌 데이터를 분석에 포함시킨다.\n",
        "- **비선형 관계**: '직선'이 아닌 '곡선' 관계를 잡아낸다.\n",
        "- **상호작용 항**: '누구에게나 똑같은 효과'가 아닌, '그룹별로 다른 효과'를 잡아낸다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **1. 더미 변수 (Dummy Variables)**\n",
        "\n",
        "- **목적**: '성별(남/여)', '지역(수도권/비수도권)', '정책 시행 여부(Yes/No)' 등 숫자로 표현되지 않는 **질적(categorical) 데이터**를 회귀분석에 포함시키기 위한 방법.\n",
        "- **만드는 법**: 특정 카테고리에 해당하면 **1**, 해당하지 않으면 **0**의 값을 갖는 변수를 만든다.\n",
        "    - 예: `male` 더미 변수 → 남성이면 1, 여성이면 0.\n",
        "- **해석**:\n",
        "    - **모형**: $$ \\widehat{wage_i} = \\hat{\\beta}_0 + \\hat{\\beta}_1 education_i + \\hat{\\beta}_2 male_i $$\n",
        "    - **$\\hat{\\beta}_2$의 의미**: 기준 그룹(여기서는 여성, `male`=0)에 비해, `male`=1인 그룹(남성)의 임금이 **평균적으로 얼마나 더 높은가(혹은 낮은가)**를 나타낸다. 즉, '그룹 간 평균 차이'를 보여준다.\n",
        "- **주의점 (더미 변수 함정)**: 카테고리가 3개 이상일 때(예: 수도권/영남/호남), 기준이 될 그룹 하나를 제외하고 **(n-1)개의 더미 변수**만 모델에 포함시켜야 한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **2. 비선형 관계 (Non-linear Relationships)**\n",
        "\n",
        "- **목적**: 변수 간의 관계가 항상 직선적이지는 않을 때, **곡선(curved) 관계**를 모델에 반영하는 방법.\n",
        "- **주요 기술**:\n",
        "    1.  **다항 회귀 (Polynomial Regression)**: 독립변수의 **제곱항($X^2$), 세제곱항($X^3$)** 등을 모델에 추가하여 U자형, 역U자형 등 다양한 형태의 곡선을 표현한다.\n",
        "        - **모형 (제곱항)**: $$ Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 X_i^2 + u_i $$\n",
        "        - **예시**: '나이'와 '소득'의 관계. 소득은 청년기에 증가하다가 중장년기에 정점을 찍고 노년기에 감소하는 **역U자형** 관계를 보인다.\n",
        "\n",
        "    2.  **로그 변환 (Log Transformations)**: 변수에 자연로그(ln)를 취하여, 모델을 **'증가율(%)'**의 관계로 해석할 수 있게 만들어준다. 경제학에서 가장 널리 쓰이는 변환 중 하나이다.\n",
        "        - **모형 (log-lin)**: $$ \\log(Y_i) = \\beta_0 + \\beta_1 X_i + u_i $$\n",
        "        - **$\\beta_1$의 해석**: X가 1단위 증가할 때, Y는 평균적으로 **$(\\beta_1 \\times 100)\\%$ 만큼 변화**한다.\n",
        "        - **예시**: \"교육이 1년 늘면, 임금은 평균적으로 8% 증가한다.\"\n",
        "\n",
        "<br>\n",
        "\n",
        "### **3. 상호작용 항 (Interaction Terms)**\n",
        "\n",
        "- **목적**: 한 독립변수($X_1$)의 효과가 다른 독립변수($X_2$)의 수준이나 그룹에 따라 **체계적으로 달라지는 효과**를 잡아내기 위함.\n",
        "- **만드는 법**: 두 독립변수를 서로 곱한 새로운 변수($X_1 \\times X_2$)를 만들어 회귀식에 추가한다.\n",
        "- **해석**:\n",
        "    - **연구 질문**: \"교육의 임금 상승 효과가 남성과 여성에게서 다르게 나타날까?\"\n",
        "    - **모형**: $$ \\widehat{wage_i} = \\hat{\\beta}_0 + \\hat{\\beta}_1 education_i + \\hat{\\beta}_2 male_i + \\hat{\\beta}_3 (education_i \\times male_i) $$\n",
        "    - **해석**:\n",
        "        - **여성 (`male`=0)의 교육 효과**: $\\hat{\\beta}_1$\n",
        "        - **남성 (`male`=1)의 교육 효과**: $\\hat{\\beta}_1 + \\hat{\\beta}_3$\n",
        "        - **$\\hat{\\beta}_3$의 의미**: **핵심 해석 부분.** 여성에 비해 남성의 교육 수익률이 **평균적으로 얼마나 더 높은가(혹은 낮은가)**를 나타낸다. 즉, 그룹 간 '기울기의 차이'를 보여준다."
      ],
      "metadata": {
        "id": "Ji7a9kLRQLOu"
      }
    }
  ]
}