{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **파트 4: 머신러닝 예측 방법론**\n",
        "\n",
        "---\n",
        "# 23. 머신러닝 예측의 세계: 새로운 패러다임\n",
        "\n",
        "### **핵심 아이디어: 무엇이 다른가?**\n",
        "- **전통적 통계/계량 모델 (Statistical Modeling)**:\n",
        "    - **목표**: 데이터 생성 과정에 대한 **'이해'와 '해석'**. (`Y = βX + u` 라는 '구조'를 가정하고, β의 의미를 해석하는 데 중점)\n",
        "    - **접근법**: 연구자가 먼저 이론에 기반한 간단한 모델을 설정하고, 데이터가 이 모델에 얼마나 잘 맞는지를 평가한다. **'가설 주도(Hypothesis-driven)'** 방식.\n",
        "\n",
        "- **머신러닝 (Machine Learning)**:\n",
        "    - **목표**: 주어진 데이터를 이용해 **'정확한 예측'**을 하는 것. 모델의 내부 구조가 어떻게 생겼는지보다, 그래서 'Out-of-Sample 예측 오차'가 얼마나 작은지에만 집중한다.\n",
        "    - **접근법**: 복잡한 구조를 가진 알고리즘에 데이터를 대량으로 투입하여, 알고리즘이 **데이터로부터 패턴을 '스스로 학습(learn)'**하도록 한다. **'데이터 주도(Data-driven)'** 방식.\n",
        "\n",
        "- **비유**:\n",
        "    - **전통적 계량**: 물리학자가 F=ma라는 **'단순하고 명확한 법칙'**을 먼저 세우고, 공의 움직임이 이 법칙을 따르는지 확인하는 것.\n",
        "    - **머신러닝**: 수많은 공의 움직임 데이터를 컴퓨터에 보여주고, 컴퓨터가 그 움직임을 가장 잘 예측하는 **복잡하지만 정확한 '규칙의 집합'**을 스스로 찾아내게 하는 것.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **머신러닝의 종류**\n",
        "머신러닝은 학습 방식에 따라 크게 세 가지로 나뉜다.\n",
        "\n",
        "1.  **지도 학습 (Supervised Learning)**\n",
        "    - **정의**: **'정답(Y)'이 있는 데이터**를 가지고 학습하는 방식. 우리가 앞으로 다룰 대부분의 예측 모델이 여기에 속한다.\n",
        "    - **하위 종류**:\n",
        "        - **회귀 (Regression)**: Y가 연속적인 값(예: 주가, 임금)일 때, 그 값을 예측.\n",
        "        - **분류 (Classification)**: Y가 특정 카테고리(예: '개/고양이', '생존/사망')일 때, 어떤 카테고리에 속할지 예측.\n",
        "    - **우리가 배울 모델**: 라쏘/릿지, 랜덤 포레스트, 부스팅, SVM, RNN/LSTM 등은 모두 지도 학습에 속한다.\n",
        "\n",
        "2.  **비지도 학습 (Unsupervised Learning)**\n",
        "    - **정의**: **'정답(Y)'이 없는 데이터**에서 숨겨진 구조나 패턴을 찾아내는 방식.\n",
        "    - **주요 과업**:\n",
        "        - **군집화 (Clustering)**: 비슷한 데이터들을 그룹으로 묶는 것. (예: 고객 세분화)\n",
        "        - **차원 축소 (Dimensionality Reduction)**: 수많은 변수들을 더 적은 수의 핵심적인 변수로 요약하는 것. (예: 주성분 분석, PCA)\n",
        "\n",
        "3.  **강화 학습 (Reinforcement Learning)**\n",
        "    - **정의**: 어떤 '환경(environment)' 안에서, 에이전트(agent)가 '보상(reward)'을 최대화하는 행동(action)을 시행착오를 통해 학습하는 방식. (예: 알파고, 자율주행)\n",
        "    - (경제학에서는 동태적 최적화 문제 등과 관련이 있지만, 지금 우리의 로드맵에서는 직접적으로 다루지 않는다.)\n",
        "\n",
        "<br>\n",
        "\n",
        "### **이 챕터에서 다룰 내용**\n",
        "이제 우리는 **'지도 학습'**의 세계, 그중에서도 주로 **'회귀'** 문제를 중심으로, OLS의 한계를 극복하는 다양한 현대적 예측 모델들을 탐험할 것이다. 이 모델들은 나중에 **'대주제 5: 머신러닝 인과추론'**에서 OVB 문제를 해결하는 강력한 부품으로 재활용될 것이다."
      ],
      "metadata": {
        "id": "fT3GXqaTYM5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 24. Regularization (정규화): 라쏘(Lasso)와 릿지(Ridge)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 우리가 '대주제 1'에서 다뤘던 OLS는 변수가 매우 많아질 때(high-dimensional data) 두 가지 큰 문제에 직면한다: **과적합(overfitting)**과 **다중공선성(multicollinearity)**.\n",
        "- **정규화(Regularization)**는 OLS 모델에 일종의 **'페널티(penalty)' 또는 '제약'**을 부과하여, 이 문제들을 해결하는 방법론이다.\n",
        "- 모델이 너무 복잡해지는 것을 막고(과적합 방지), 변수들 간의 강한 상관관계(다중공선성) 속에서도 안정적인 예측을 하도록 돕는다. OLS의 직접적인 확장판이자, 머신러닝 예측의 가장 기본이 되는 개념이다.\n",
        "- **비유**: 아이에게 \"점수를 최대한 높게 받아와!\"라고만 하면(OLS의 목표: 잔차 제곱합 최소화), 컨닝을 하거나 꼼수를 쓸 수 있다(과적합). 여기에 \"단, 정직하게 풀어야 한다\"는 **'규칙(페널티)'**을 추가해주는 것이 바로 정규화이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **어떻게 페널티를 부과하는가?**\n",
        "OLS의 목표는 **잔차 제곱합(SSR)**을 최소화하는 것이었다. 정규화 회귀는 여기에 **'회귀계수($\\beta$)의 크기'**에 대한 페널티 항을 추가한다.\n",
        "\n",
        "$$\n",
        "\\text{최소화 목표} = \\underbrace{\\sum (Y_i - \\hat{Y}_i)^2}_\\text{SSR (데이터에 대한 적합도)} + \\underbrace{\\lambda \\cdot P(\\beta)}_\\text{페널티 (모델의 복잡도)}\n",
        "$$\n",
        "\n",
        "- $P(\\beta)$: 회귀계수들의 크기를 측정하는 함수.\n",
        "- $\\lambda$ (람다): **튜닝 파라미터(Tuning Parameter)**. 페널티의 '강도'를 조절한다.\n",
        "    - $\\lambda=0$ 이면, 페널티가 없으므로 OLS와 똑같아진다.\n",
        "    - $\\lambda$가 커질수록, 페널티가 강해져서 회귀계수($\\beta$)들의 크기가 점점 '0'에 가깝게 줄어든다(shrinkage).\n",
        "\n",
        "<br>\n",
        "\n",
        "### **두 종류의 정규화: 릿지 vs. 라쏘**\n",
        "페널티를 부과하는 방식($P(\\beta)$)에 따라 크게 두 가지로 나뉜다.\n",
        "\n",
        "1.  **릿지 회귀 (Ridge Regression)**\n",
        "    - **페널티 방식**: 회귀계수들의 **'제곱합'**에 페널티를 부과한다. (L2-norm)\n",
        "        $$ P(\\beta) = \\sum \\beta_j^2 $$\n",
        "    - **특징**:\n",
        "        - 계수들을 0에 '가깝게' 만들지만, 정확히 '0'으로 만들지는 않는다.\n",
        "        - 따라서 모든 변수를 모델에 포함시키되, 그 영향력을 전반적으로 줄여주는 역할을 한다.\n",
        "        - 독립변수들 간의 다중공선성이 매우 높을 때, OLS보다 훨씬 더 안정적인 성능을 보인다.\n",
        "\n",
        "2.  **라쏘 회귀 (Lasso Regression)**\n",
        "    - **페널티 방식**: 회귀계수들의 **'절댓값의 합'**에 페널티를 부과한다. (L1-norm)\n",
        "        $$ P(\\beta) = \\sum |\\beta_j| $$\n",
        "    - **특징**:\n",
        "        - 페널티의 강도($\\lambda$)가 충분히 커지면, 중요하지 않은 변수의 계수를 **정확히 '0'으로** 만들어 버린다.\n",
        "        - 이는 모델이 예측에 도움이 되지 않는 변수를 **자동으로 '선택'하고 '제거'**하는 효과를 가진다. 이를 **변수 선택(Feature Selection)**이라고 한다.\n",
        "        - 수백, 수천 개의 변수 중 소수의 중요한 변수만 골라내어 더 간결하고 해석하기 쉬운 모델을 만들고 싶을 때 매우 유용하다.\n",
        "        - **DML과 같은 머신러닝 인과추론에서 통제변수를 처리할 때 가장 핵심적인 부품**으로 사용된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **실용적인 요약**\n",
        "\n",
        "| 구분 | **릿지 (Ridge)** | **라쏘 (Lasso)** |\n",
        "| :--- | :--- | :--- |\n",
        "| **페널티** | 계수의 제곱합 ($L_2$) | 계수의 절댓값 합 ($L_1$) |\n",
        "| **주요 효과**| 계수를 0에 가깝게 축소 (Shrinkage) | 계수를 0으로 만듦 (Variable Selection) |\n",
        "| **강점** | **다중공선성**이 심할 때 안정적 | **고차원 데이터**에서 변수 선택이 필요할 때 |\n",
        "| **인과추론 연결**| | **DML의 핵심 엔진** |"
      ],
      "metadata": {
        "id": "g_Ti08WxrxK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 25. 트리 기반 모델: 랜덤 포레스트 (Random Forest)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- \"집단지성이 개인의 지성보다 뛰어나다\"는 아이디어를 기반으로 한다.\n",
        "- 예측력이 그리 좋지 않은 수많은 **'단순한 의사결정나무(Decision Tree)'**들을 대량으로 만들고, 이들의 예측 결과를 **'종합(앙상블, Ensemble)'**하여 최종 예측값을 얻는 방식이다.\n",
        "- 나무(tree)들이 모여 숲(forest)을 이루는 것처럼, 수많은 의사결정나무들이 모여 랜덤 포레스트를 구성한다.\n",
        "- **비유**: 어려운 문제를 풀 때, 한 명의 천재 전문가(복잡한 단일 모델)에게 의존하는 것이 아니라, 수백 명의 평범한 학생들(단순한 나무)에게 각자 풀게 한 뒤, 가장 많이 나온 답을 채택하는 '다수결' 또는 '평균' 방식을 사용하는 것과 같다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **랜덤 포레스트의 두 가지 핵심 부품**\n",
        "\n",
        "#### **1. 의사결정나무 (Decision Tree)**\n",
        "- **정의**: 데이터를 '예/아니오' 형태의 질문(분기)을 반복하여 특정 그룹으로 분류하거나 예측값을 할당하는, 나무 형태의 모델.\n",
        "- **작동 방식**: 데이터의 불순도(impurity)를 가장 크게 낮추거나, 예측 오차를 가장 크게 줄이는 질문(예: \"나이가 30세 이상인가?\", \"소득이 5천만 원 이상인가?\")을 찾아 데이터를 두 개의 그룹으로 나눈다. 이 과정을 반복하여 나무를 성장시킨다.\n",
        "- **한계**: 나무를 너무 깊게 성장시키면, 훈련 데이터의 아주 사소한 패턴까지 모두 학습하여 **과적합(overfitting)**이 발생하기 매우 쉽다. 즉, '나무 하나'는 똑똑하지만 아주 편협한 전문가와 같다.\n",
        "\n",
        "#### **2. 앙상블 기법: 배깅 (Bagging, Bootstrap Aggregating)**\n",
        "- **정의**: 과적합되기 쉬운 불안정한 모델들을 안정시키는 데 사용하는 매우 강력한 앙상블 기법.\n",
        "- **작동 방식**:\n",
        "    1.  **부트스트랩 (Bootstrap)**: 원본 훈련 데이터에서 **무작위로 복원을 허용하여** 여러 개의 '미니 훈련 데이터셋'을 만든다. 각 미니 데이터셋은 원본 데이터와 크기는 같지만, 일부 데이터는 중복되고 일부는 누락된다.\n",
        "    2.  **모델링 (Aggregating)**: 각각의 미니 데이터셋을 사용하여 **독립적으로** 수백, 수천 개의 의사결정나무 모델을 학습시킨다.\n",
        "    3.  **결과 종합 (Voting/Averaging)**:\n",
        "        - **분류 문제(Y가 0/1)**: 모든 나무들이 예측한 결과 중, 가장 많은 표를 받은 값(다수결)을 최종 예측값으로 선택한다.\n",
        "        - **회귀 문제(Y가 연속형)**: 모든 나무들이 예측한 값들의 '평균'을 최종 예측값으로 선택한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **랜덤 포레스트는 어떻게 '랜덤'해지는가?**\n",
        "배깅에 더해, 랜덤 포레스트는 한 가지 '무작위성'을 더 추가하여 개별 나무들이 서로 다른 특징을 갖도록 유도한다.\n",
        "\n",
        "- **특성(변수) 무작위 선택 (Random Feature Selection)**: 나무의 각 분기점을 찾을 때, **전체 독립변수(X)를 모두 고려하는 것이 아니라, 그중 일부 변수만을 무작위로 선택**하여 최적의 질문을 찾도록 한다.\n",
        "- **효과**: 이렇게 하면, 각각의 나무들은 데이터의 서로 다른 측면을 학습하게 된다. 특정 변수 하나가 예측력이 너무 강해서 모든 나무들이 비슷한 모양이 되는 것을 방지하고, **'다양성'을 극대화**하여 숲 전체의 예측력을 향상시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점**\n",
        "- **높은 예측 정확도**: 현존하는 예측 모델 중 가장 성능이 뛰어난 모델 중 하나이다.\n",
        "- **과적합 방지**: 수많은 나무들의 결과를 평균내므로, 개별 나무의 과적합 문제가 크게 줄어든다.\n",
        "- **자동으로 비선형/상호작용 탐지**: '대주제 1'에서 다뤘던 비선형 관계나 상호작용 항을 연구자가 수동으로 넣어줄 필요 없이, 나무 구조가 알아서 데이터의 복잡한 패턴을 학습한다.\n",
        "- **변수 중요도(Feature Importance)**: 어떤 변수가 예측에 가장 중요한 역할을 했는지를 측정해준다.\n"
      ],
      "metadata": {
        "id": "4KuzrJitufwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 26. 트리 기반 모델 (2): 부스팅 (Boosting)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- 랜덤 포레스트와 마찬가지로 '약한 학습기(weak learner)'인 의사결정나무를 여러 개 사용하는 앙상블 기법이지만, 작동 방식은 정반대이다.\n",
        "- **랜덤 포레스트**: 수많은 나무들을 **'병렬적(parallel)'**으로, 그리고 **'독립적으로'** 학습시켜 그 결과를 민주적으로 종합(평균/다수결)한다. (협동하는 천재 집단)\n",
        "- **부스팅**: 간단한 나무를 **'순차적(sequential)'**으로 만들어 나가되, **앞선 나무가 틀린 문제(오차)를 다음 나무가 집중적으로 학습하여 보완**해나가는 방식이다.\n",
        "- **비유**: 여러 명의 학생이 함께 **'오답노트'**를 푸는 것과 같다.\n",
        "    1. 첫 번째 학생(나무1)이 시험을 보고 몇 문제를 틀린다(오차 발생).\n",
        "    2. 두 번째 학생(나무2)은 전체 문제를 다 푸는 대신, 첫 번째 학생이 **틀린 문제에 가중치를 부여**받아 그 문제들을 집중적으로 푼다.\n",
        "    3. 세 번째 학생(나무3)은 앞선 두 학생이 여전히 잘 못 푸는 문제들을 집중적으로 학습한다.\n",
        "    4. 이 과정을 반복하여, 결국 모든 문제 유형에 대한 전문가들로 구성된 '최강의 팀'을 만든다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **작동 원리 (Gradient Boosting을 중심으로)**\n",
        "가장 널리 쓰이는 그래디언트 부스팅의 원리는 다음과 같다.\n",
        "\n",
        "1.  **첫 번째 예측**: 아주 간단한 모델(예: 전체 데이터의 평균값)로 첫 예측($\\hat{y}_1$)을 한다.\n",
        "2.  **오차 계산**: 실제값($y$)과 첫 예측값($\\hat{y}_1$) 사이의 차이, 즉 **잔차(residual)**를 계산한다. 이 잔차가 바로 첫 모델이 '설명하지 못한 부분'이다.\n",
        "3.  **오차 학습**: 새로운 의사결정나무(나무2)를 만든다. 이 나무의 목표는 $y$를 예측하는 것이 아니라, **앞 단계에서 계산된 '잔차'를 예측**하는 것이다.\n",
        "4.  **모델 업데이트**: 기존 예측값($\\hat{y}_1$)에, 잔차를 예측한 나무2의 결과 일부(learning rate를 곱하여)를 더하여 예측 모델($\\hat{y}_2$)을 업데이트한다.\n",
        "5.  **반복**: 새로운 예측 모델($\\hat{y}_2$)의 잔차를 계산하고, 다음 나무(나무3)는 이 새로운 잔차를 학습하는 과정을 수백, 수천 번 반복한다.\n",
        "\n",
        "- 최종적으로, 부스팅 모델은 **'기본 모델 + (첫 번째 오차 수정 모델) + (두 번째 오차 수정 모델) + ...'** 와 같은 형태로 구성된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **주요 알고리즘**\n",
        "- **Gradient Boosting Machine (GBM)**: 그래디언트 부스팅의 기본이 되는 알고리즘.\n",
        "- **XGBoost, LightGBM, CatBoost**: GBM의 속도와 성능을 극적으로 개선한 현대적인 알고리즘들. 데이터 과학 경진대회(Kaggle 등)에서 예측 성능으로 순위를 다툴 때 가장 많이 사용되는 '최강의 무기'들이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점과 단점**\n",
        "- **장점**:\n",
        "    - **최고 수준의 예측 정확도**: 많은 경우, 다른 어떤 알고리즘보다도 높은 예측 성능을 보여 '성능의 끝판왕'으로 불린다.\n",
        "    - **높은 유연성**: 다양한 종류의 손실 함수(loss function)를 사용할 수 있고, 파라미터 튜닝을 통해 모델을 매우 정교하게 만들 수 있다.\n",
        "\n",
        "- **단점**:\n",
        "    - **과적합(Overfitting) 민감성**: 모델을 순차적으로 보완해나가므로, 너무 많이 학습시키면 훈련 데이터의 노이즈까지 학습할 위험이 크다. 학습률(learning rate), 나무의 수 등 파라미터를 신중하게 튜닝(tuning)해야 한다.\n",
        "    - **느린 학습 속도**: 나무를 하나씩 순차적으로 만들어야 하므로, 병렬 처리가 쉬운 랜덤 포레스트에 비해 학습 시간이 오래 걸릴 수 있다."
      ],
      "metadata": {
        "id": "NPprx2BvM6h5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 27. 서포트 벡터 머신 (Support Vector Machine, SVM)\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어**\n",
        "- SVM은 **분류(classification)** 문제를 푸는 데에서 출발한 모델로, **서로 다른 그룹의 데이터들을 가장 잘 나누는 '경계선(decision boundary)'을 찾는 것**을 목표로 한다.\n",
        "- 단순히 두 그룹을 나누는 선을 긋는 것을 넘어, 각 그룹의 데이터로부터 **가장 멀리 떨어져 있는, 가장 안정적인 '최적의 경계선'**을 찾으려고 한다.\n",
        "- **비유**: 바닥에 파란 구슬과 빨간 구슬이 흩어져 있을 때, 이 두 그룹을 나누기 위해 막대기 하나를 놓는다고 상상해보자.\n",
        "    - **나쁜 경계선**: 특정 구슬 그룹에 너무 가깝게 붙어 있는 막대기. 새로운 구슬이 들어왔을 때 잘못 분류할 위험이 크다.\n",
        "    - **좋은 경계선(SVM이 찾는 것)**: 양쪽 그룹의 가장 가까운 구슬들로부터 **'최대한 멀리' 떨어져 있는 중앙의 막대기.** 이 막대기는 새로운 구슬에 대해 더 강건한(robust) 분류 기준이 된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **SVM의 주요 개념**\n",
        "\n",
        "1.  **마진 (Margin)**\n",
        "    - **정의**: 경계선과, 그 경계선에서 가장 가까이 있는 각 그룹의 데이터 포인트(점) 사이의 **'거리'**.\n",
        "    - **SVM의 목표**: 이 **마진의 폭을 '최대화(Maximizing the Margin)'**하는 최적의 경계선을 찾는 것. 마진이 넓을수록 모델이 더 안정적이고 일반화 성능이 높다고 본다.\n",
        "\n",
        "2.  **서포트 벡터 (Support Vectors)**\n",
        "    - **정의**: 이 마진을 결정하는 데 직접적으로 관여하는, **경계선에 가장 가까이 위치한 데이터 포인트들.**\n",
        "    - **의미**: SVM 모델은 오직 이 '서포트 벡터'들에 의해서만 결정된다. 나머지 멀리 떨어져 있는 데이터들은 모델을 만드는 데 아무런 영향을 주지 않는다. 즉, 가장 '중요한' 데이터 몇 개에만 집중하여 경계선을 만드는, 매우 효율적인 방식이다.\n",
        "\n",
        "3.  **커널 트릭 (The Kernel Trick)**\n",
        "    - **SVM의 진정한 슈퍼파워.**\n",
        "    - **문제**: 현실의 데이터는 직선(선형) 경계선 하나만으로는 완벽하게 나눌 수 없는 경우가 많다. (예: 안쪽에 파란 구슬이 있고, 바깥쪽에 빨간 구슬이 원형으로 둘러싸고 있는 경우)\n",
        "    - **해법**: 데이터를 현재의 차원(예: 2차원 평면)에서 **더 높은 차원의 공간(예: 3차원 공간)으로 '순간이동'** 시킨다.\n",
        "    - **커널 트릭의 마법**: 저차원에서는 복잡하게 얽혀 있어 직선으로 나눌 수 없었던 데이터들이, **고차원으로 옮겨가면 신기하게도 단순한 평면(초평면)으로 나눌 수 있게 된다.**\n",
        "    - **장점**: 이 '순간이동' 과정을 실제로 계산하지 않고도, 마치 계산한 것과 같은 효과를 내주는 수학적 트릭이다. 이를 통해 SVM은 매우 복잡한 **비선형(non-linear) 경계선**을 효율적으로 찾아낼 수 있다.\n",
        "    - **대표적인 커널**: RBF (Radial Basis Function) 커널, 다항(Polynomial) 커널 등.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **회귀(Regression) 문제로의 확장**\n",
        "- SVM은 분류뿐만 아니라 회귀(SVR, Support Vector Regression)에도 사용될 수 있다.\n",
        "- **SVR의 아이디어**: 마진을 최대화하는 분류와 반대로, 이번에는 특정 폭을 가진 **'튜브(tube)'**를 만들고, **그 튜브 안에 최대한 많은 데이터가 들어가도록** 최적의 회귀선을 찾는다. 튜브 바깥으로 벗어나는 데이터에 대해서만 오차로 간주하여 페널티를 부여한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **장점과 단점**\n",
        "- **장점**:\n",
        "    - **고차원 데이터에 강함**: 변수가 매우 많은(high-dimensional) 데이터, 특히 변수 수(p)가 데이터 수(n)보다 많은 경우에도 잘 작동한다.\n",
        "    - **강력한 비선형 모델링**: 커널 트릭을 통해 매우 복잡한 비선형 관계도 효과적으로 학습할 수 있다.\n",
        "    - **이론적 견고함**: 마진 최대화라는 명확한 수학적 원리에 기반하고 있어, 이론적으로 매우 우아하고 안정적이다.\n",
        "\n",
        "- **단점**:\n",
        "    - **계산 속도**: 데이터가 매우 커지면 학습 속도가 느려질 수 있다.\n",
        "    - **해석의 어려움 (블랙박스)**: 어떤 변수가 왜 중요한지, 변수 간의 관계가 어떤지를 직관적으로 해석하기가 어렵다. (라쏘나 의사결정나무에 비해)\n",
        "    - **파라미터 튜닝**: 어떤 커널을 사용할지, 마진의 폭을 어떻게 조절할지 등 최적의 성능을 내기 위해 여러 파라미터를 신중하게 튜닝해야 한다."
      ],
      "metadata": {
        "id": "NMPh5_ifOxYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 28. 딥러닝과 시계열 예측: RNN & LSTM\n",
        "\n",
        "---\n",
        "\n",
        "### **핵심 아이디어: 왜 순환 신경망(RNN)인가?**\n",
        "- 지금까지 다룬 모든 모델(OLS, 랜덤 포레스트, SVM 등)은 데이터의 **'순서'를 고려하지 않는다**는 치명적인 한계가 있다. 각 관측치는 서로 독립적이라고 가정한다.\n",
        "- 하지만 시계열 데이터(예: 주가)나 텍스트 데이터(예: 문장)는 **순서 자체가 핵심적인 정보**를 담고 있다. (예: \"나는 너를 사랑해\" vs \"너는 나를 사랑해\")\n",
        "- **순환 신경망(Recurrent Neural Network, RNN)**은 이전 단계(time step)의 정보를 **'기억'**하여 다음 단계의 입력으로 함께 사용하는, 즉 **'순환하는' 구조**를 가진 신경망이다. 이를 통해 데이터의 순차적인 맥락을 학습할 수 있다.\n",
        "- **비유**: 우리가 책을 읽을 때, 현재 문장을 이해하기 위해 바로 앞 문단의 내용을 기억하는 것과 같다. RNN의 '기억' 역할을 하는 부분을 **'은닉 상태(hidden state)'**라고 부른다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **기본 RNN의 구조와 한계**\n",
        "\n",
        "- **구조**: RNN은 $t$ 시점의 데이터를 처리할 때, $t$ 시점의 입력값($X_t$)과 **바로 이전 단계($t-1$)에서 계산된 은닉 상태($h_{t-1}$)**를 함께 입력받아 현재의 은닉 상태($h_t$)를 만든다. 이 과정이 시퀀스가 끝날 때까지 반복된다.\n",
        "\n",
        "- **한계: 장기 의존성 문제 (Long-Term Dependency Problem)**\n",
        "    - 기본 RNN은 마치 **'단기 기억상실증'**에 걸린 사람과 같다.\n",
        "    - 순서가 길어질수록, 맨 처음에 들어왔던 중요한 정보의 영향력이 뒤로 갈수록 점점 희미해지거나(**기울기 소실, Vanishing Gradient**), 반대로 너무 과도하게 증폭되어(기울기 폭발, Exploding Gradient) 학습이 제대로 이루어지지 않는다.\n",
        "    - **예시**: \"나는 프랑스에서 태어나 자랐고, ... (중간에 긴 문장들) ... 그래서 나는 ...를 유창하게 구사한다.\" 라는 문장이 있을 때, 빈칸에 '프랑스어'가 들어가야 한다는 것을 예측하려면 맨 처음의 '프랑스'라는 단어를 기억해야 하지만, 기본 RNN은 중간의 긴 문장들을 거치면서 이 정보를 잊어버리기 쉽다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **해결책: LSTM (Long Short-Term Memory)**\n",
        "\n",
        "- **핵심 아이디어**: LSTM은 기본 RNN의 '단기 기억상실증' 문제를 해결하기 위해 고안된, 훨씬 더 정교하고 강력한 RNN의 한 종류이다.\n",
        "- **작동 원리**: LSTM의 핵심에는 **'게이트(Gate)'**라는 장치가 있다. 이 게이트들은 마치 정보의 흐름을 조절하는 '밸브'처럼 작동하여, 어떤 정보를 기억하고, 어떤 정보를 잊어버리고, 어떤 정보를 출력할지를 **선택적으로 학습**한다.\n",
        "    - **비유**: LSTM 셀은 단순히 정보를 기억하는 메모리가 아니라, **'게이트 키퍼'**가 있는 정교한 정보 관리 시스템과 같다.\n",
        "\n",
        "- **LSTM의 3가지 핵심 게이트**:\n",
        "    1.  **Forget Gate (삭제 게이트)**: 과거의 정보($h_{t-1}$) 중에서, **'잊어버릴(버릴) 정보'**를 결정한다. (예: 새로운 문단의 주어가 등장했으니, 이전 문단의 주어는 이제 잊어버리자.)\n",
        "    2.  **Input Gate (입력 게이트)**: 현재 들어온 정보($X_t$) 중에서, **'기억할 만한 가치가 있는 새로운 정보'**를 선별하여 저장한다. (예: '프랑스'라는 새로운 장소 정보가 등장했으니, 이것은 중요하므로 장기 기억에 저장하자.)\n",
        "    3.  **Output Gate (출력 게이트)**: 이렇게 업데이트된 기억 중에서, **'지금 당장 필요한 정보'**가 무엇인지를 결정하여 다음 단계로 출력($h_t$)한다. (예: 현재 문장의 동사를 예측해야 하니, 방금 저장한 '프랑스'가 아니라 '주어'에 대한 정보를 출력하자.)\n",
        "\n",
        "- **결론**: 이 게이트 구조 덕분에 LSTM은 필요하다면 아주 오래전의 정보도 잊지 않고 기억하여, **장기 의존성 문제를 매우 효과적으로 해결**할 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **주요 사용처 및 다른 모델과의 관계**\n",
        "- **주요 사용처**:\n",
        "    - **자연어 처리 (NLP)**: 기계 번역, 챗봇, 감성 분석 등 텍스트 데이터 분석의 거의 모든 영역.\n",
        "    - **음성 인식**\n",
        "    - **복잡한 시계열 예측**: 주가, 날씨, 전력 수요 등 ARIMA/VAR과 같은 전통적 모델로는 잡아내기 어려운 복잡하고 비선형적인 패턴을 가진 시계열 데이터 예측.\n",
        "- **ARIMA/VAR과의 관계**: 전통적인 시계열 모델의 **'딥러닝 버전'**이라고 할 수 있다. ARIMA/VAR가 통계학적 구조와 가정에 기반한다면, RNN/LSTM은 데이터로부터 복잡한 패턴을 직접 학습하는 데 더 중점을 둔다."
      ],
      "metadata": {
        "id": "QD2iBlJaQUaM"
      }
    }
  ]
}